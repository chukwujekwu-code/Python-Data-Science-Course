{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13: Introduction to Machine Learning\n",
    "\n",
    "## Topics Covered\n",
    "1. What is Machine Learning?\n",
    "2. Types of ML (Supervised, Unsupervised, Reinforcement)\n",
    "3. The ML Workflow\n",
    "4. Train-Test Split\n",
    "5. Overview of Common Algorithms (Linear Regression, Logistic Regression, Decision Trees)\n",
    "6. Model Evaluation Concepts\n",
    "7. Cross-Validation\n",
    "8. Introduction to Scikit-Learn\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "- Explain what machine learning is and identify different types of ML problems\n",
    "- Understand the complete machine learning workflow from problem definition to deployment\n",
    "- Split data into training and testing sets properly\n",
    "- Recognize common machine learning algorithms and when to use them\n",
    "- Understand fundamental evaluation concepts for regression and classification\n",
    "- Apply cross-validation techniques to assess model performance\n",
    "- Use scikit-learn's consistent API for machine learning tasks\n",
    "- Build complete ML pipelines with preprocessing and modeling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries we'll use throughout this module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,\n",
    "                             accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris, load_boston, make_classification\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: What is Machine Learning?\n",
    "---\n",
    "\n",
    "## Definition\n",
    "\n",
    "Machine Learning (ML) is a subset of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed for each specific task.\n",
    "\n",
    "### Traditional Programming vs Machine Learning\n",
    "\n",
    "**Traditional Programming:**\n",
    "```\n",
    "Data + Rules → Program → Output\n",
    "```\n",
    "\n",
    "**Machine Learning:**\n",
    "```\n",
    "Data + Output → ML Algorithm → Rules (Model)\n",
    "```\n",
    "\n",
    "### Why Machine Learning?\n",
    "\n",
    "Machine learning is useful when:\n",
    "- Rules are too complex to code manually (e.g., image recognition)\n",
    "- Rules change over time (e.g., spam detection)\n",
    "- Patterns are not obvious to humans (e.g., customer behavior)\n",
    "- Personalization is required (e.g., recommendations)\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "| Domain | Application |\n",
    "|--------|-------------|\n",
    "| Healthcare | Disease diagnosis, drug discovery |\n",
    "| Finance | Fraud detection, credit scoring |\n",
    "| Retail | Product recommendations, demand forecasting |\n",
    "| Transportation | Self-driving cars, route optimization |\n",
    "| Marketing | Customer segmentation, churn prediction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example: Traditional programming vs ML approach\n",
    "# Task: Predict house prices\n",
    "\n",
    "# Traditional approach - explicit rules (oversimplified)\n",
    "def predict_price_traditional(sqft, bedrooms, location_score):\n",
    "    \"\"\"Manual rules for house pricing - hard to get right!\"\"\"\n",
    "    base_price = 50000\n",
    "    price = base_price + (sqft * 100) + (bedrooms * 10000) + (location_score * 20000)\n",
    "    return price\n",
    "\n",
    "# ML approach - learn from data\n",
    "# Generate synthetic housing data\n",
    "np.random.seed(42)\n",
    "n_houses = 100\n",
    "\n",
    "sqft = np.random.uniform(1000, 3000, n_houses)\n",
    "bedrooms = np.random.randint(1, 6, n_houses)\n",
    "location_score = np.random.uniform(1, 10, n_houses)\n",
    "\n",
    "# True relationship (unknown to us in real scenarios)\n",
    "actual_prices = (50000 + sqft * 150 + bedrooms * 15000 + \n",
    "                 location_score * 25000 + np.random.normal(0, 20000, n_houses))\n",
    "\n",
    "# Create DataFrame\n",
    "housing_data = pd.DataFrame({\n",
    "    'sqft': sqft,\n",
    "    'bedrooms': bedrooms,\n",
    "    'location_score': location_score,\n",
    "    'price': actual_prices\n",
    "})\n",
    "\n",
    "print(\"Sample Housing Data:\")\n",
    "print(housing_data.head(10))\n",
    "print(f\"\\nDataset shape: {housing_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare traditional vs ML predictions\n",
    "# Traditional prediction\n",
    "housing_data['traditional_pred'] = housing_data.apply(\n",
    "    lambda row: predict_price_traditional(row['sqft'], row['bedrooms'], row['location_score']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ML prediction (Linear Regression - we'll learn this soon)\n",
    "X = housing_data[['sqft', 'bedrooms', 'location_score']]\n",
    "y = housing_data['price']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "housing_data['ml_pred'] = model.predict(X)\n",
    "\n",
    "# Compare errors\n",
    "traditional_error = np.sqrt(mean_squared_error(housing_data['price'], housing_data['traditional_pred']))\n",
    "ml_error = np.sqrt(mean_squared_error(housing_data['price'], housing_data['ml_pred']))\n",
    "\n",
    "print(\"Prediction Error Comparison (RMSE):\")\n",
    "print(f\"  Traditional rules: ${traditional_error:,.2f}\")\n",
    "print(f\"  Machine Learning:  ${ml_error:,.2f}\")\n",
    "print(f\"\\nML model reduces error by {((traditional_error - ml_error) / traditional_error * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Types of Machine Learning\n",
    "---\n",
    "\n",
    "## Three Main Categories\n",
    "\n",
    "### 1. Supervised Learning\n",
    "- Learning from labeled data (input-output pairs)\n",
    "- Goal: Learn a mapping from inputs to outputs\n",
    "- Examples: Spam detection, price prediction, image classification\n",
    "\n",
    "**Two types:**\n",
    "- **Regression**: Predict continuous values (e.g., house prices)\n",
    "- **Classification**: Predict categories (e.g., spam vs. not spam)\n",
    "\n",
    "### 2. Unsupervised Learning\n",
    "- Learning from unlabeled data\n",
    "- Goal: Find patterns or structure in data\n",
    "- Examples: Customer segmentation, anomaly detection\n",
    "\n",
    "**Common techniques:**\n",
    "- Clustering (K-means, hierarchical)\n",
    "- Dimensionality reduction (PCA)\n",
    "- Association rules\n",
    "\n",
    "### 3. Reinforcement Learning\n",
    "- Learning through interaction with an environment\n",
    "- Goal: Maximize cumulative reward\n",
    "- Examples: Game playing, robotics, autonomous vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of Supervised Learning types\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Regression example\n",
    "np.random.seed(42)\n",
    "x_reg = np.linspace(0, 10, 50)\n",
    "y_reg = 2 * x_reg + 3 + np.random.normal(0, 2, 50)\n",
    "\n",
    "axes[0].scatter(x_reg, y_reg, alpha=0.6)\n",
    "axes[0].plot(x_reg, 2 * x_reg + 3, color='red', linewidth=2, label='Predicted line')\n",
    "axes[0].set_xlabel('Feature (X)')\n",
    "axes[0].set_ylabel('Target (Y) - Continuous')\n",
    "axes[0].set_title('Regression: Predict Continuous Values')\n",
    "axes[0].legend()\n",
    "\n",
    "# Classification example\n",
    "from sklearn.datasets import make_blobs\n",
    "X_class, y_class = make_blobs(n_samples=100, centers=2, random_state=42, cluster_std=1.5)\n",
    "\n",
    "colors = ['blue' if label == 0 else 'orange' for label in y_class]\n",
    "axes[1].scatter(X_class[:, 0], X_class[:, 1], c=colors, alpha=0.6)\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].set_title('Classification: Predict Categories')\n",
    "\n",
    "# Add legend manually\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='blue', label='Class 0'),\n",
    "                   Patch(facecolor='orange', label='Class 1')]\n",
    "axes[1].legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised Learning example: Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate unlabeled data\n",
    "np.random.seed(42)\n",
    "X_unlabeled, _ = make_blobs(n_samples=150, centers=3, random_state=42, cluster_std=1.0)\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_unlabeled)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before clustering\n",
    "axes[0].scatter(X_unlabeled[:, 0], X_unlabeled[:, 1], alpha=0.6)\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].set_title('Before Clustering (No Labels)')\n",
    "\n",
    "# After clustering\n",
    "scatter = axes[1].scatter(X_unlabeled[:, 0], X_unlabeled[:, 1], \n",
    "                          c=cluster_labels, cmap='viridis', alpha=0.6)\n",
    "axes[1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                marker='X', s=200, c='red', edgecolor='black', linewidth=2,\n",
    "                label='Cluster Centers')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].set_title('After K-Means Clustering')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: The Machine Learning Workflow\n",
    "---\n",
    "\n",
    "## Standard ML Pipeline\n",
    "\n",
    "```\n",
    "1. Define Problem → 2. Collect Data → 3. Prepare Data → 4. Explore Data\n",
    "                                                              ↓\n",
    "8. Deploy Model ← 7. Fine-tune ← 6. Evaluate Model ← 5. Build Model\n",
    "```\n",
    "\n",
    "### Step-by-Step Breakdown\n",
    "\n",
    "1. **Define the Problem**\n",
    "   - What are you trying to predict?\n",
    "   - Is it regression or classification?\n",
    "   - What metrics define success?\n",
    "\n",
    "2. **Collect Data**\n",
    "   - Gather relevant data\n",
    "   - Ensure data quality\n",
    "   - Consider data privacy\n",
    "\n",
    "3. **Prepare Data**\n",
    "   - Handle missing values\n",
    "   - Encode categorical variables\n",
    "   - Scale/normalize features\n",
    "\n",
    "4. **Explore Data (EDA)**\n",
    "   - Understand distributions\n",
    "   - Identify patterns and correlations\n",
    "   - Detect outliers\n",
    "\n",
    "5. **Build Model**\n",
    "   - Select algorithm(s)\n",
    "   - Split data (train/test)\n",
    "   - Train the model\n",
    "\n",
    "6. **Evaluate Model**\n",
    "   - Test on unseen data\n",
    "   - Calculate performance metrics\n",
    "   - Compare with baseline\n",
    "\n",
    "7. **Fine-tune**\n",
    "   - Adjust hyperparameters\n",
    "   - Try different algorithms\n",
    "   - Feature engineering\n",
    "\n",
    "8. **Deploy**\n",
    "   - Put model into production\n",
    "   - Monitor performance\n",
    "   - Update as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's walk through a complete ML workflow example\n",
    "# Problem: Predict if a customer will make a purchase based on their behavior\n",
    "\n",
    "# Step 1: Define Problem\n",
    "print(\"STEP 1: Define Problem\")\n",
    "print(\"=\"*50)\n",
    "print(\"Task: Predict customer purchase (Yes/No)\")\n",
    "print(\"Type: Binary Classification\")\n",
    "print(\"Success Metric: Accuracy, with focus on Recall\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 & 3: Collect and Prepare Data\n",
    "print(\"STEP 2 & 3: Collect and Prepare Data\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generate synthetic customer data\n",
    "np.random.seed(42)\n",
    "n_customers = 500\n",
    "\n",
    "customer_data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 70, n_customers),\n",
    "    'income': np.random.normal(50000, 20000, n_customers).clip(20000, 150000),\n",
    "    'time_on_site': np.random.exponential(5, n_customers),  # minutes\n",
    "    'pages_viewed': np.random.poisson(5, n_customers),\n",
    "    'previous_purchases': np.random.poisson(2, n_customers),\n",
    "    'email_subscribed': np.random.choice([0, 1], n_customers, p=[0.4, 0.6])\n",
    "})\n",
    "\n",
    "# Create target variable (purchase) based on features\n",
    "purchase_probability = (\n",
    "    0.1 + \n",
    "    0.01 * (customer_data['income'] / 10000) +\n",
    "    0.05 * customer_data['time_on_site'] +\n",
    "    0.03 * customer_data['pages_viewed'] +\n",
    "    0.1 * customer_data['previous_purchases'] +\n",
    "    0.15 * customer_data['email_subscribed']\n",
    ").clip(0, 1)\n",
    "\n",
    "customer_data['purchased'] = np.random.binomial(1, purchase_probability)\n",
    "\n",
    "print(f\"Dataset shape: {customer_data.shape}\")\n",
    "print(f\"\\nFeatures: {list(customer_data.columns[:-1])}\")\n",
    "print(f\"Target: purchased\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(customer_data['purchased'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(customer_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Explore Data (Quick EDA)\n",
    "print(\"STEP 4: Explore Data\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(customer_data.describe().round(2))\n",
    "\n",
    "# Correlation with target\n",
    "print(\"\\nCorrelation with 'purchased':\")\n",
    "correlations = customer_data.corr()['purchased'].drop('purchased').sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions by purchase status\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "features = ['age', 'income', 'time_on_site', 'pages_viewed', 'previous_purchases', 'email_subscribed']\n",
    "\n",
    "for ax, feature in zip(axes.flat, features):\n",
    "    if feature == 'email_subscribed':\n",
    "        # Bar plot for binary feature\n",
    "        customer_data.groupby(['email_subscribed', 'purchased']).size().unstack().plot(\n",
    "            kind='bar', ax=ax, alpha=0.7)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.legend(['No Purchase', 'Purchase'])\n",
    "    else:\n",
    "        # Histogram for continuous features\n",
    "        customer_data[customer_data['purchased']==0][feature].hist(\n",
    "            ax=ax, alpha=0.5, label='No Purchase', bins=20)\n",
    "        customer_data[customer_data['purchased']==1][feature].hist(\n",
    "            ax=ax, alpha=0.5, label='Purchase', bins=20)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.legend()\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Train-Test Split\n",
    "---\n",
    "\n",
    "## Why Split the Data?\n",
    "\n",
    "We need to evaluate our model on data it hasn't seen during training. This helps us:\n",
    "\n",
    "1. **Estimate real-world performance**: How well will the model work on new data?\n",
    "2. **Detect overfitting**: Is the model memorizing training data instead of learning patterns?\n",
    "3. **Compare models fairly**: Consistent evaluation across different models\n",
    "\n",
    "### Common Split Ratios\n",
    "\n",
    "| Split | Training | Testing | Use Case |\n",
    "|-------|----------|---------|----------|\n",
    "| 80/20 | 80% | 20% | Most common, general purpose |\n",
    "| 70/30 | 70% | 30% | When you need more test data |\n",
    "| 90/10 | 90% | 10% | Large datasets |\n",
    "\n",
    "### Important Considerations\n",
    "\n",
    "- **Random sampling**: Ensure representative splits\n",
    "- **Stratification**: Maintain class proportions in imbalanced datasets\n",
    "- **No data leakage**: Test data should never influence training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Basic split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,              # Features\n",
    "    y,              # Target\n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42 # For reproducibility\n",
    ")\n",
    "\n",
    "# Stratified split (for classification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,     # Maintain class proportions\n",
    "    random_state=42\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 (Part 1): Split the data\n",
    "print(\"STEP 5 (Part 1): Train-Test Split\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Separate features and target\n",
    "X = customer_data.drop('purchased', axis=1)\n",
    "y = customer_data['purchased']\n",
    "\n",
    "# Split with stratification (important for imbalanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Testing samples: {len(X_test)} ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "\n",
    "print(f\"\\nClass distribution in original data:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the split\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Dataset sizes\n",
    "sizes = [len(X_train), len(X_test)]\n",
    "labels = [f'Training\\n({len(X_train)} samples)', f'Testing\\n({len(X_test)} samples)']\n",
    "colors = ['steelblue', 'coral']\n",
    "axes[0].pie(sizes, labels=labels, colors=colors, autopct='%1.0f%%', startangle=90)\n",
    "axes[0].set_title('Train-Test Split')\n",
    "\n",
    "# Class distribution\n",
    "x_pos = np.arange(2)\n",
    "width = 0.35\n",
    "\n",
    "train_dist = y_train.value_counts().sort_index().values\n",
    "test_dist = y_test.value_counts().sort_index().values\n",
    "\n",
    "bars1 = axes[1].bar(x_pos - width/2, train_dist, width, label='Training', color='steelblue')\n",
    "bars2 = axes[1].bar(x_pos + width/2, test_dist, width, label='Testing', color='coral')\n",
    "\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Class Distribution After Split')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(['No Purchase (0)', 'Purchase (1)'])\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: Overview of Common Machine Learning Algorithms\n",
    "---\n",
    "\n",
    "In this section, we'll briefly introduce three fundamental machine learning algorithms. Linear and Logistic Regression will be previewed here and covered in depth in dedicated modules. Decision Trees will be fully explored in this module.\n",
    "\n",
    "## Algorithm Types\n",
    "\n",
    "| Algorithm | Type | Use Case | Covered In |\n",
    "|-----------|------|----------|------------|\n",
    "| Linear Regression | Regression | Predict continuous values | Module 14 |\n",
    "| Logistic Regression | Classification | Predict binary outcomes | Module 15 |\n",
    "| Decision Trees | Both | Interpretable models | This Module (Full Coverage) |\n",
    "\n",
    "---\n",
    "\n",
    "## Linear Regression (Preview)\n",
    "\n",
    "Linear regression is the simplest supervised learning algorithm for regression tasks. It models the relationship between features and a continuous target by fitting a straight line (or hyperplane).\n",
    "\n",
    "**Equation:** `y = b0 + b1*x1 + b2*x2 + ... + bn*xn`\n",
    "\n",
    "**When to use:**\n",
    "- Predicting continuous values (prices, temperatures, sales)\n",
    "- Understanding linear relationships between variables\n",
    "- When interpretability is important\n",
    "\n",
    "**Key strengths:**\n",
    "- Fast to train\n",
    "- Highly interpretable coefficients\n",
    "- Works well with linearly separable data\n",
    "\n",
    "**Note:** Module 14 covers Linear Regression in detail, including polynomial regression, regularization (Ridge, Lasso), and advanced diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick example: Linear Regression syntax (full coverage in Module 14)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Use housing data from Section 1\n",
    "X_house = housing_data[['sqft', 'bedrooms', 'location_score']]\n",
    "y_house = housing_data['price']\n",
    "\n",
    "# Simple sklearn API pattern\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_house, y_house)\n",
    "\n",
    "print(\"Linear Regression Model Created!\")\n",
    "print(f\"Coefficients: {model_lr.coef_}\")\n",
    "print(f\"Intercept: ${model_lr.intercept_:,.2f}\")\n",
    "print(f\"\\nThis demonstrates the basic sklearn API pattern.\")\n",
    "print(f\"We'll explore this algorithm in depth in Module 14.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Logistic Regression (Preview)\n",
    "\n",
    "Despite its name, logistic regression is a **classification** algorithm. It predicts the probability that an observation belongs to a particular class using the sigmoid function.\n",
    "\n",
    "**How it works:**\n",
    "1. Calculates a linear combination of features\n",
    "2. Applies sigmoid function: `P(y=1) = 1 / (1 + e^(-z))`\n",
    "3. Converts probability to class label using threshold (usually 0.5)\n",
    "\n",
    "**When to use:**\n",
    "- Binary classification (spam/not spam, fraud/legit)\n",
    "- When you need probability estimates\n",
    "- When interpretability is important\n",
    "\n",
    "**Key strengths:**\n",
    "- Provides probability estimates\n",
    "- Works well with linearly separable classes\n",
    "- Fast and efficient\n",
    "\n",
    "**Note:** Module 15 covers Logistic Regression in detail, including multiclass classification, decision boundaries, ROC curves, and class imbalance handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick example: Logistic Regression syntax (full coverage in Module 15)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Use customer data from Section 3\n",
    "X_customer = customer_data.drop('purchased', axis=1)\n",
    "y_customer = customer_data['purchased']\n",
    "\n",
    "# Scale features (good practice for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_customer)\n",
    "\n",
    "# Same sklearn API pattern!\n",
    "model_log = LogisticRegression(random_state=42)\n",
    "model_log.fit(X_scaled, y_customer)\n",
    "\n",
    "# Make predictions\n",
    "sample_prediction = model_log.predict(X_scaled[:5])\n",
    "sample_probabilities = model_log.predict_proba(X_scaled[:5])\n",
    "\n",
    "print(\"Logistic Regression Model Created!\")\n",
    "print(f\"First 5 predictions: {sample_prediction}\")\n",
    "print(f\"First 5 probabilities (class 0, class 1):\")\n",
    "print(sample_probabilities)\n",
    "print(f\"\\nNotice the consistent sklearn API: fit(), predict(), predict_proba()\")\n",
    "print(f\"We'll explore this algorithm in depth in Module 15.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Decision Trees (Full Coverage)\n\nDecision trees are versatile algorithms that can perform both classification and regression. Unlike Linear and Logistic Regression which we'll cover in dedicated modules, we'll fully explore Decision Trees here as a foundational algorithm.\n\n### How They Work\n\n1. Start with all data at the root node\n2. Find the best feature and value to split the data\n3. Create child nodes for each split\n4. Repeat until stopping criteria are met\n5. Assign predictions at leaf nodes\n\n### Advantages\n\n- Easy to understand and interpret\n- Handle both numerical and categorical data\n- Require little data preprocessing\n- Can capture non-linear relationships\n\n### Disadvantages\n\n- Prone to overfitting\n- Can be unstable (small changes in data = different tree)\n- May create biased trees with imbalanced data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# For Classification\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=5,           # Limit tree depth to prevent overfitting\n",
    "    min_samples_split=10,  # Minimum samples to split a node\n",
    "    min_samples_leaf=5,    # Minimum samples in a leaf\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# For Regression\n",
    "reg = DecisionTreeRegressor(\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Feature importance\n",
    "importances = clf.feature_importances_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree for customer purchase prediction\n",
    "print(\"Decision Tree: Customer Purchase Prediction\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create and train model (use unscaled data - trees don't need scaling)\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=4,          # Limit depth to prevent overfitting and aid visualization\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"\\nDecision Tree Accuracy: {accuracy_dt:.4f} ({accuracy_dt*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=['No Purchase', 'Purchase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Decision Tree Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_model, \n",
    "          feature_names=X_train.columns,\n",
    "          class_names=['No Purchase', 'Purchase'],\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models: Logistic Regression vs Decision Tree\n",
    "print(\"Model Comparison\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Logistic Regression': [\n",
    "        accuracy_score(y_test, y_pred_class),\n",
    "        precision_score(y_test, y_pred_class),\n",
    "        recall_score(y_test, y_pred_class),\n",
    "        f1_score(y_test, y_pred_class)\n",
    "    ],\n",
    "    'Decision Tree': [\n",
    "        accuracy_score(y_test, y_pred_dt),\n",
    "        precision_score(y_test, y_pred_dt),\n",
    "        recall_score(y_test, y_pred_dt),\n",
    "        f1_score(y_test, y_pred_dt)\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df['Logistic Regression'] = comparison_df['Logistic Regression'].round(4)\n",
    "comparison_df['Decision Tree'] = comparison_df['Decision Tree'].round(4)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Model Evaluation Concepts\n",
    "---\n",
    "\n",
    "## Why Evaluation Matters\n",
    "\n",
    "After training a model, we need to assess how well it performs. The metrics we use depend on the problem type: regression or classification.\n",
    "\n",
    "## Regression Metrics\n",
    "\n",
    "For predicting continuous values (like prices, temperatures):\n",
    "\n",
    "| Metric | What It Measures | Interpretation |\n",
    "|--------|-----------------|----------------|\n",
    "| MSE | Mean Squared Error | Lower is better; penalizes large errors heavily |\n",
    "| RMSE | Root Mean Squared Error | Same units as target; easier to interpret than MSE |\n",
    "| MAE | Mean Absolute Error | Average absolute difference; robust to outliers |\n",
    "| R² | R-squared | Proportion of variance explained (0-1, higher is better) |\n",
    "\n",
    "**When to use which:**\n",
    "- Use **R²** for overall model quality\n",
    "- Use **RMSE** when large errors are particularly bad\n",
    "- Use **MAE** when all errors should be weighted equally\n",
    "\n",
    "## Classification Metrics\n",
    "\n",
    "For predicting categories (like spam/not spam, fraud/legit):\n",
    "\n",
    "| Metric | What It Measures | When to Prioritize |\n",
    "|--------|-----------------|-------------------|\n",
    "| Accuracy | Overall correctness | Balanced datasets |\n",
    "| Precision | Correctness of positive predictions | When false positives are costly |\n",
    "| Recall | Coverage of actual positives | When false negatives are costly |\n",
    "| F1-Score | Balance between precision and recall | When you need both |\n",
    "\n",
    "### The Confusion Matrix\n",
    "\n",
    "```\n",
    "                  Predicted\n",
    "                  Negative    Positive\n",
    "Actual  Negative     TN         FP\n",
    "        Positive     FN         TP\n",
    "```\n",
    "\n",
    "- **True Positive (TP)**: Correctly predicted positive\n",
    "- **True Negative (TN)**: Correctly predicted negative\n",
    "- **False Positive (FP)**: Incorrectly predicted positive (Type I error)\n",
    "- **False Negative (FN)**: Incorrectly predicted negative (Type II error)\n",
    "\n",
    "**Formulas:**\n",
    "- Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "- Precision = TP / (TP + FP)\n",
    "- Recall = TP / (TP + FN)\n",
    "- F1-Score = 2 × (Precision × Recall) / (Precision + Recall)\n",
    "\n",
    "**Note:** We'll practice calculating and interpreting these metrics extensively in Modules 14-16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# Section 7: Cross-Validation\n---\n\n## What is Cross-Validation?\n\nCross-validation is a technique to evaluate model performance more reliably by training and testing on different subsets of data multiple times.\n\n### Why Use Cross-Validation?\n\n- **More reliable estimates**: Single train-test split can be misleading\n- **Better use of data**: All data points are used for both training and testing\n- **Detect overfitting**: Large gap between training and CV scores indicates overfitting\n\n### K-Fold Cross-Validation\n\n1. Split data into K equal folds\n2. For each fold:\n   - Use that fold as test set\n   - Use remaining K-1 folds as training set\n   - Calculate performance metric\n3. Average the K results"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "# Basic cross-validation\n",
    "scores = cross_val_score(\n",
    "    model,           # The model to evaluate\n",
    "    X,               # Features\n",
    "    y,               # Target\n",
    "    cv=5,            # Number of folds\n",
    "    scoring='accuracy'  # Metric to use\n",
    ")\n",
    "\n",
    "print(f\"Mean: {scores.mean():.4f}\")\n",
    "print(f\"Std: {scores.std():.4f}\")\n",
    "\n",
    "# Custom K-Fold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "# Stratified K-Fold (for classification)\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=skfold)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-Fold Cross-Validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create sample data indices\n",
    "n_samples = 25\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "# Set up 5-fold CV\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(indices)):\n",
    "    # Plot training indices\n",
    "    ax.scatter(train_idx, [fold_idx] * len(train_idx), c='steelblue', s=100, \n",
    "               label='Training' if fold_idx == 0 else '')\n",
    "    # Plot test indices\n",
    "    ax.scatter(test_idx, [fold_idx] * len(test_idx), c='coral', s=100,\n",
    "               label='Testing' if fold_idx == 0 else '')\n",
    "\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Fold')\n",
    "ax.set_yticks(range(5))\n",
    "ax.set_yticklabels([f'Fold {i+1}' for i in range(5)])\n",
    "ax.set_title('5-Fold Cross-Validation Visualization')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cross-validation to our models\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "print(\"Cross-Validation Results (5-Fold)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use stratified K-fold for classification\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_cv = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_scores = cross_val_score(lr_cv, scaler.fit_transform(X), y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nLogistic Regression:\")\n",
    "print(f\"  Scores per fold: {[f'{s:.4f}' for s in lr_scores]}\")\n",
    "print(f\"  Mean accuracy: {lr_scores.mean():.4f} (+/- {lr_scores.std()*2:.4f})\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_cv = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dt_scores = cross_val_score(dt_cv, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nDecision Tree:\")\n",
    "print(f\"  Scores per fold: {[f'{s:.4f}' for s in dt_scores]}\")\n",
    "print(f\"  Mean accuracy: {dt_scores.mean():.4f} (+/- {dt_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models with multiple metrics using cross-validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_cv_results = cross_validate(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    scaler.fit_transform(X), y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "dt_cv_results = cross_validate(\n",
    "    DecisionTreeClassifier(max_depth=4, random_state=42),\n",
    "    X, y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Create comparison table\n",
    "print(\"Comprehensive Cross-Validation Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric in scoring:\n",
    "    lr_test = lr_cv_results[f'test_{metric}']\n",
    "    dt_test = dt_cv_results[f'test_{metric}']\n",
    "    \n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Logistic Regression: {lr_test.mean():.4f} (+/- {lr_test.std()*2:.4f})\")\n",
    "    print(f\"  Decision Tree:       {dt_test.mean():.4f} (+/- {dt_test.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validation results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "lr_means = [lr_cv_results[f'test_{m.lower()}'].mean() for m in metrics]\n",
    "lr_stds = [lr_cv_results[f'test_{m.lower()}'].std() for m in metrics]\n",
    "dt_means = [dt_cv_results[f'test_{m.lower()}'].mean() for m in metrics]\n",
    "dt_stds = [dt_cv_results[f'test_{m.lower()}'].std() for m in metrics]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, lr_means, width, yerr=lr_stds, label='Logistic Regression', capsize=5)\n",
    "bars2 = ax.bar(x + width/2, dt_means, width, yerr=dt_stds, label='Decision Tree', capsize=5)\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Cross-Validation Results Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# Section 8: Introduction to Scikit-Learn\n---\n\n## What is Scikit-Learn?\n\nScikit-learn is the most popular machine learning library in Python. It provides:\n\n- **Simple and consistent API**: All models follow the same pattern\n- **Comprehensive algorithms**: Classification, regression, clustering, etc.\n- **Data preprocessing tools**: Scaling, encoding, imputation\n- **Model selection utilities**: Cross-validation, hyperparameter tuning\n- **Excellent documentation**: Well-documented with examples\n\n## The Scikit-Learn API Pattern\n\nAll scikit-learn estimators follow the same pattern:\n\n```python\n# 1. Import\nfrom sklearn.module import EstimatorClass\n\n# 2. Instantiate\nmodel = EstimatorClass(hyperparameters)\n\n# 3. Fit (train)\nmodel.fit(X_train, y_train)\n\n# 4. Predict\npredictions = model.predict(X_test)\n\n# 5. Evaluate\nscore = model.score(X_test, y_test)\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of common scikit-learn modules\n",
    "print(\"Scikit-Learn Module Overview\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "modules = [\n",
    "    (\"sklearn.linear_model\", \"Linear models\", \n",
    "     [\"LinearRegression\", \"LogisticRegression\", \"Ridge\", \"Lasso\"]),\n",
    "    (\"sklearn.tree\", \"Tree-based models\",\n",
    "     [\"DecisionTreeClassifier\", \"DecisionTreeRegressor\"]),\n",
    "    (\"sklearn.ensemble\", \"Ensemble methods\",\n",
    "     [\"RandomForestClassifier\", \"GradientBoostingClassifier\"]),\n",
    "    (\"sklearn.svm\", \"Support Vector Machines\",\n",
    "     [\"SVC\", \"SVR\"]),\n",
    "    (\"sklearn.neighbors\", \"Nearest Neighbors\",\n",
    "     [\"KNeighborsClassifier\", \"KNeighborsRegressor\"]),\n",
    "    (\"sklearn.cluster\", \"Clustering\",\n",
    "     [\"KMeans\", \"DBSCAN\", \"AgglomerativeClustering\"]),\n",
    "    (\"sklearn.preprocessing\", \"Data preprocessing\",\n",
    "     [\"StandardScaler\", \"MinMaxScaler\", \"LabelEncoder\"]),\n",
    "    (\"sklearn.model_selection\", \"Model selection\",\n",
    "     [\"train_test_split\", \"cross_val_score\", \"GridSearchCV\"]),\n",
    "    (\"sklearn.metrics\", \"Evaluation metrics\",\n",
    "     [\"accuracy_score\", \"mean_squared_error\", \"confusion_matrix\"])\n",
    "]\n",
    "\n",
    "for module, description, classes in modules:\n",
    "    print(f\"\\n{module}\")\n",
    "    print(f\"  {description}\")\n",
    "    print(f\"  Classes: {', '.join(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete ML pipeline with scikit-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Building a Complete ML Pipeline\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a pipeline that combines preprocessing and modeling\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),           # Step 1: Scale features\n",
    "    ('classifier', LogisticRegression())    # Step 2: Train classifier\n",
    "])\n",
    "\n",
    "# Fit the entire pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the pipeline\n",
    "y_pred_pipeline = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"\\nPipeline Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Cross-validate the entire pipeline\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(f\"\\nCross-Validation Scores: {[f'{s:.4f}' for s in cv_scores]}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Hyperparameter Tuning with GridSearchCV\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [5, 10, 20],\n",
    "    'min_samples_leaf': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Plot heatmap of results for different max_depth and min_samples_split\n",
    "# (fixing min_samples_leaf at the best value)\n",
    "best_leaf = grid_search.best_params_['min_samples_leaf']\n",
    "subset = results_df[results_df['param_min_samples_leaf'] == best_leaf]\n",
    "\n",
    "pivot_table = subset.pivot_table(\n",
    "    values='mean_test_score',\n",
    "    index='param_max_depth',\n",
    "    columns='param_min_samples_split'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.4f', cmap='YlGnBu')\n",
    "plt.title(f'Grid Search Results (min_samples_leaf={best_leaf})')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('max_depth')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 10.1\n",
    "\n",
    "**Task:** Use scikit-learn to build a complete machine learning solution for the Iris dataset.\n",
    "\n",
    "Steps:\n",
    "1. Load the Iris dataset using `load_iris()`\n",
    "2. Split into training and testing sets\n",
    "3. Create a pipeline with StandardScaler and LogisticRegression\n",
    "4. Perform 5-fold cross-validation\n",
    "5. Use GridSearchCV to tune the `C` parameter (try [0.01, 0.1, 1, 10, 100])\n",
    "6. Report the best parameters and test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(f\"Dataset shape: {X_iris.shape}\")\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Classes: {iris.target_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 10.1\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# Step 1: Load dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(\"Step 1: Load Dataset\")\n",
    "print(f\"  Shape: {X_iris.shape}\")\n",
    "print(f\"  Classes: {list(iris.target_names)}\")\n",
    "\n",
    "# Step 2: Split data\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, stratify=y_iris, random_state=42\n",
    ")\n",
    "print(f\"\\nStep 2: Split Data\")\n",
    "print(f\"  Training samples: {len(X_train_i)}\")\n",
    "print(f\"  Testing samples: {len(X_test_i)}\")\n",
    "\n",
    "# Step 3: Create pipeline\n",
    "pipeline_iris = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "print(f\"\\nStep 3: Pipeline Created\")\n",
    "print(f\"  Steps: {[step[0] for step in pipeline_iris.steps]}\")\n",
    "\n",
    "# Step 4: Cross-validation\n",
    "cv_scores_iris = cross_val_score(pipeline_iris, X_train_i, y_train_i, cv=5)\n",
    "print(f\"\\nStep 4: Cross-Validation\")\n",
    "print(f\"  Scores: {[f'{s:.4f}' for s in cv_scores_iris]}\")\n",
    "print(f\"  Mean: {cv_scores_iris.mean():.4f} (+/- {cv_scores_iris.std()*2:.4f})\")\n",
    "\n",
    "# Step 5: GridSearchCV\n",
    "param_grid_iris = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_iris = GridSearchCV(pipeline_iris, param_grid_iris, cv=5, scoring='accuracy')\n",
    "grid_iris.fit(X_train_i, y_train_i)\n",
    "\n",
    "print(f\"\\nStep 5: GridSearchCV\")\n",
    "print(f\"  Best C: {grid_iris.best_params_['classifier__C']}\")\n",
    "print(f\"  Best CV Score: {grid_iris.best_score_:.4f}\")\n",
    "\n",
    "# Step 6: Final evaluation\n",
    "test_accuracy_iris = grid_iris.score(X_test_i, y_test_i)\n",
    "print(f\"\\nStep 6: Final Evaluation\")\n",
    "print(f\"  Test Set Accuracy: {test_accuracy_iris:.4f}\")\n",
    "\n",
    "# Detailed results\n",
    "print(f\"\\nClassification Report:\")\n",
    "y_pred_iris = grid_iris.predict(X_test_i)\n",
    "print(classification_report(y_test_i, y_pred_iris, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Module Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### What is Machine Learning?\n",
    "- ML enables computers to learn patterns from data without explicit programming\n",
    "- Three main types: Supervised, Unsupervised, and Reinforcement Learning\n",
    "- Supervised learning includes regression (continuous) and classification (categorical)\n",
    "\n",
    "### The ML Workflow\n",
    "1. Define the problem\n",
    "2. Collect and prepare data\n",
    "3. Explore data (EDA)\n",
    "4. Build and train models\n",
    "5. Evaluate performance\n",
    "6. Fine-tune and deploy\n",
    "\n",
    "### Train-Test Split\n",
    "- Always split data before training to evaluate on unseen data\n",
    "- Common ratio: 80% training, 20% testing\n",
    "- Use stratification for imbalanced classification problems\n",
    "\n",
    "### Common Algorithms\n",
    "- **Linear Regression**: Predicts continuous values (covered in Module 14)\n",
    "- **Logistic Regression**: Binary classification (covered in Module 15)\n",
    "- **Decision Trees**: Interpretable, handles non-linear relationships\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Regression**: MSE, RMSE, MAE, R-squared\n",
    "- **Classification**: Accuracy, Precision, Recall, F1-score\n",
    "- Choose metrics based on business context (e.g., recall for fraud detection)\n",
    "\n",
    "### Cross-Validation\n",
    "- More reliable than single train-test split\n",
    "- K-Fold CV uses all data for both training and testing\n",
    "- Report mean and standard deviation of scores\n",
    "\n",
    "### Scikit-Learn\n",
    "- Consistent API across all algorithms: `fit()`, `predict()`, `score()`\n",
    "- Pipelines combine preprocessing and modeling\n",
    "- GridSearchCV for hyperparameter tuning\n",
    "\n",
    "## Next Modules\n",
    "\n",
    "Now that you understand the machine learning fundamentals and workflow, we'll dive deep into specific algorithms:\n",
    "\n",
    "- **Module 14: Linear Regression** - Full coverage including polynomial regression, regularization, and diagnostics\n",
    "- **Module 15: Logistic Regression** - Complete treatment of binary and multiclass classification\n",
    "- **Module 16: Classification Algorithms** - K-NN, Naive Bayes, and SVM\n",
    "\n",
    "## Additional Practice\n",
    "\n",
    "For extra practice, try these challenges:\n",
    "1. Load the wine or breast cancer dataset from sklearn and apply the complete ML workflow\n",
    "2. Compare Decision Tree, Linear Regression, and Logistic Regression on appropriate datasets\n",
    "3. Create an end-to-end pipeline with preprocessing, modeling, and cross-validation\n",
    "4. Experiment with different train-test split ratios and observe the impact on model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}