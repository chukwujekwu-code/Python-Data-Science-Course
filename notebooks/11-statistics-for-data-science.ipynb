{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11: Statistics for Data Science\n",
    "\n",
    "## Topics Covered\n",
    "1. Descriptive Statistics\n",
    "2. Measures of Central Tendency\n",
    "3. Measures of Dispersion\n",
    "4. Probability Basics\n",
    "5. Probability Distributions\n",
    "6. Hypothesis Testing Fundamentals\n",
    "7. Correlation and Covariance\n",
    "8. A/B Testing Basics\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "- Calculate and interpret descriptive statistics for datasets\n",
    "- Understand and apply measures of central tendency and dispersion\n",
    "- Apply basic probability concepts to data problems\n",
    "- Work with common probability distributions\n",
    "- Perform and interpret hypothesis tests\n",
    "- Calculate and interpret correlation and covariance\n",
    "- Design and analyze basic A/B tests\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries we'll use throughout this module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: Descriptive Statistics\n",
    "---\n",
    "\n",
    "## What are Descriptive Statistics?\n",
    "\n",
    "Descriptive statistics are numerical values that summarize and describe the main features of a dataset. Unlike inferential statistics (which we'll cover later), descriptive statistics don't try to make conclusions beyond the data at hand - they simply describe what's there.\n",
    "\n",
    "### Why This Matters in Data Science\n",
    "\n",
    "Descriptive statistics are your first line of defense when exploring data. Before building models or making predictions, you need to understand:\n",
    "- What does a \"typical\" value look like?\n",
    "- How spread out are the values?\n",
    "- Are there any unusual patterns or outliers?\n",
    "- What's the shape of the distribution?\n",
    "\n",
    "### Types of Descriptive Statistics\n",
    "\n",
    "1. **Measures of Central Tendency** - Where is the \"center\" of the data?\n",
    "2. **Measures of Dispersion** - How spread out is the data?\n",
    "3. **Measures of Shape** - What does the distribution look like?\n",
    "4. **Measures of Position** - Where do specific values fall in the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a sample dataset to work with\n",
    "# Simulating employee salaries at a tech company\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate salary data with different distributions for different departments\n",
    "engineering_salaries = np.random.normal(95000, 15000, 100)\n",
    "marketing_salaries = np.random.normal(75000, 12000, 60)\n",
    "sales_salaries = np.random.normal(65000, 20000, 80)  # Higher variance\n",
    "executive_salaries = np.random.normal(150000, 30000, 10)  # Small group, high salaries\n",
    "\n",
    "# Combine into a DataFrame\n",
    "salaries_df = pd.DataFrame({\n",
    "    'salary': np.concatenate([engineering_salaries, marketing_salaries, \n",
    "                              sales_salaries, executive_salaries]),\n",
    "    'department': (['Engineering'] * 100 + ['Marketing'] * 60 + \n",
    "                   ['Sales'] * 80 + ['Executive'] * 10)\n",
    "})\n",
    "\n",
    "# Ensure no negative salaries\n",
    "salaries_df['salary'] = salaries_df['salary'].clip(lower=30000)\n",
    "\n",
    "print(f\"Dataset shape: {salaries_df.shape}\")\n",
    "print(f\"\\nDepartment counts:\")\n",
    "print(salaries_df['department'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview with pandas describe()\n",
    "print(\"Overall Salary Statistics:\")\n",
    "print(salaries_df['salary'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics by department\n",
    "print(\"Salary Statistics by Department:\")\n",
    "print(salaries_df.groupby('department')['salary'].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Measures of Central Tendency\n",
    "---\n",
    "\n",
    "## What is Central Tendency?\n",
    "\n",
    "Measures of central tendency describe where the \"center\" or \"typical value\" of a dataset lies. The three main measures are:\n",
    "\n",
    "1. **Mean** - The arithmetic average\n",
    "2. **Median** - The middle value when data is sorted\n",
    "3. **Mode** - The most frequently occurring value\n",
    "\n",
    "### When to Use Each Measure\n",
    "\n",
    "| Measure | Best Used When | Sensitive To |\n",
    "|---------|---------------|---------------|\n",
    "| Mean | Data is symmetric, no outliers | Outliers |\n",
    "| Median | Data is skewed or has outliers | Not affected by outliers |\n",
    "| Mode | Categorical data or finding most common value | Multiple modes possible |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "# Using NumPy\n",
    "np.mean(array)      # Calculate mean\n",
    "np.median(array)    # Calculate median\n",
    "\n",
    "# Using pandas\n",
    "series.mean()       # Mean of a Series\n",
    "series.median()     # Median of a Series\n",
    "series.mode()       # Mode(s) of a Series\n",
    "\n",
    "# Using scipy.stats\n",
    "stats.mode(array)   # Mode with count\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calculating measures of central tendency\n",
    "salaries = salaries_df['salary']\n",
    "\n",
    "# Mean - sum of all values divided by count\n",
    "mean_salary = salaries.mean()\n",
    "print(f\"Mean salary: ${mean_salary:,.2f}\")\n",
    "\n",
    "# Median - middle value when sorted\n",
    "median_salary = salaries.median()\n",
    "print(f\"Median salary: ${median_salary:,.2f}\")\n",
    "\n",
    "# Mode - most frequent value (less useful for continuous data)\n",
    "# For continuous data, we often look at the mode of binned data\n",
    "print(f\"\\nDifference between mean and median: ${mean_salary - median_salary:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the impact of outliers\n",
    "# Let's add an extreme outlier (CEO salary)\n",
    "\n",
    "salaries_with_outlier = pd.concat([salaries, pd.Series([500000])], ignore_index=True)\n",
    "\n",
    "print(\"Without CEO salary:\")\n",
    "print(f\"  Mean: ${salaries.mean():,.2f}\")\n",
    "print(f\"  Median: ${salaries.median():,.2f}\")\n",
    "\n",
    "print(\"\\nWith CEO salary ($500,000):\")\n",
    "print(f\"  Mean: ${salaries_with_outlier.mean():,.2f}\")\n",
    "print(f\"  Median: ${salaries_with_outlier.median():,.2f}\")\n",
    "\n",
    "print(f\"\\nMean increased by: ${salaries_with_outlier.mean() - salaries.mean():,.2f}\")\n",
    "print(f\"Median increased by: ${salaries_with_outlier.median() - salaries.median():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing mean vs median\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Without outlier\n",
    "axes[0].hist(salaries, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(salaries.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${salaries.mean():,.0f}')\n",
    "axes[0].axvline(salaries.median(), color='green', linestyle='-', linewidth=2, label=f'Median: ${salaries.median():,.0f}')\n",
    "axes[0].set_xlabel('Salary ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Salary Distribution (Without CEO)')\n",
    "axes[0].legend()\n",
    "\n",
    "# With outlier\n",
    "axes[1].hist(salaries_with_outlier, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(salaries_with_outlier.mean(), color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: ${salaries_with_outlier.mean():,.0f}')\n",
    "axes[1].axvline(salaries_with_outlier.median(), color='green', linestyle='-', linewidth=2, \n",
    "                label=f'Median: ${salaries_with_outlier.median():,.0f}')\n",
    "axes[1].set_xlabel('Salary ($)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Salary Distribution (With CEO at $500K)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode - most useful for categorical data\n",
    "# Let's look at the mode of departments\n",
    "\n",
    "department_mode = salaries_df['department'].mode()\n",
    "print(f\"Most common department: {department_mode.values[0]}\")\n",
    "\n",
    "# For numerical data, we can bin it first\n",
    "salary_bins = pd.cut(salaries_df['salary'], bins=10)\n",
    "print(f\"\\nMost common salary range: {salary_bins.mode().values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimmed mean - a compromise between mean and median\n",
    "# Removes a percentage of extreme values from both ends\n",
    "\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "# 10% trimmed mean (removes bottom and top 10%)\n",
    "trimmed = trim_mean(salaries_with_outlier, 0.1)\n",
    "\n",
    "print(\"Comparison of central tendency measures (with outlier):\")\n",
    "print(f\"  Mean: ${salaries_with_outlier.mean():,.2f}\")\n",
    "print(f\"  Trimmed Mean (10%): ${trimmed:,.2f}\")\n",
    "print(f\"  Median: ${salaries_with_outlier.median():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: Measures of Dispersion\n",
    "---\n",
    "\n",
    "## What is Dispersion?\n",
    "\n",
    "Measures of dispersion (or spread) tell us how spread out the values in a dataset are. Two datasets can have the same mean but very different spreads.\n",
    "\n",
    "### Common Measures of Dispersion\n",
    "\n",
    "1. **Range** - Difference between max and min values\n",
    "2. **Variance** - Average of squared deviations from the mean\n",
    "3. **Standard Deviation** - Square root of variance (same units as data)\n",
    "4. **Interquartile Range (IQR)** - Range of the middle 50% of data\n",
    "5. **Coefficient of Variation** - Standard deviation relative to mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "# Range\n",
    "data_range = data.max() - data.min()\n",
    "\n",
    "# Variance and Standard Deviation\n",
    "variance = data.var()          # or np.var(data)\n",
    "std_dev = data.std()           # or np.std(data)\n",
    "\n",
    "# Note: pandas uses ddof=1 (sample) by default\n",
    "# NumPy uses ddof=0 (population) by default\n",
    "sample_std = data.std(ddof=1)  # Sample standard deviation\n",
    "pop_std = data.std(ddof=0)     # Population standard deviation\n",
    "\n",
    "# Interquartile Range\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Or using scipy\n",
    "from scipy.stats import iqr\n",
    "IQR = iqr(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calculating measures of dispersion\n",
    "\n",
    "# Range\n",
    "salary_range = salaries.max() - salaries.min()\n",
    "print(f\"Salary Range: ${salary_range:,.2f}\")\n",
    "print(f\"  Min: ${salaries.min():,.2f}\")\n",
    "print(f\"  Max: ${salaries.max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance and Standard Deviation\n",
    "variance = salaries.var()\n",
    "std_dev = salaries.std()\n",
    "\n",
    "print(f\"\\nVariance: ${variance:,.2f}\")\n",
    "print(f\"Standard Deviation: ${std_dev:,.2f}\")\n",
    "\n",
    "# Interpretation: Most salaries fall within 1-2 standard deviations of the mean\n",
    "mean = salaries.mean()\n",
    "print(f\"\\nMean +/- 1 Std Dev: ${mean - std_dev:,.2f} to ${mean + std_dev:,.2f}\")\n",
    "print(f\"Mean +/- 2 Std Dev: ${mean - 2*std_dev:,.2f} to ${mean + 2*std_dev:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify: What percentage actually falls within these ranges?\n",
    "within_1_std = ((salaries >= mean - std_dev) & (salaries <= mean + std_dev)).mean() * 100\n",
    "within_2_std = ((salaries >= mean - 2*std_dev) & (salaries <= mean + 2*std_dev)).mean() * 100\n",
    "\n",
    "print(f\"Percentage within 1 std dev: {within_1_std:.1f}%\")\n",
    "print(f\"Percentage within 2 std dev: {within_2_std:.1f}%\")\n",
    "print(\"\\n(For a normal distribution, these would be ~68% and ~95%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interquartile Range (IQR)\n",
    "Q1 = salaries.quantile(0.25)\n",
    "Q2 = salaries.quantile(0.50)  # Same as median\n",
    "Q3 = salaries.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(\"Quartiles:\")\n",
    "print(f\"  Q1 (25th percentile): ${Q1:,.2f}\")\n",
    "print(f\"  Q2 (50th percentile/Median): ${Q2:,.2f}\")\n",
    "print(f\"  Q3 (75th percentile): ${Q3:,.2f}\")\n",
    "print(f\"\\nInterquartile Range (IQR): ${IQR:,.2f}\")\n",
    "print(f\"\\nThe middle 50% of salaries fall between ${Q1:,.2f} and ${Q3:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of Variation (CV) - useful for comparing variability across different scales\n",
    "cv = (std_dev / mean) * 100\n",
    "print(f\"Coefficient of Variation: {cv:.2f}%\")\n",
    "\n",
    "# Compare CV across departments\n",
    "print(\"\\nCoefficient of Variation by Department:\")\n",
    "for dept in salaries_df['department'].unique():\n",
    "    dept_salaries = salaries_df[salaries_df['department'] == dept]['salary']\n",
    "    dept_cv = (dept_salaries.std() / dept_salaries.mean()) * 100\n",
    "    print(f\"  {dept}: {dept_cv:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing dispersion with a box plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "salaries_df.boxplot(column='salary', by='department', ax=ax)\n",
    "ax.set_ylabel('Salary ($)')\n",
    "ax.set_title('Salary Distribution by Department')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 3.1\n",
    "\n",
    "**Task:** You have test scores from two classes. Calculate the measures of central tendency and dispersion for each class, then determine which class performed more consistently.\n",
    "\n",
    "```python\n",
    "class_a = [85, 90, 78, 92, 88, 76, 95, 89, 84, 91]\n",
    "class_b = [82, 95, 70, 98, 75, 88, 100, 65, 93, 84]\n",
    "```\n",
    "\n",
    "Calculate for each class:\n",
    "1. Mean and Median\n",
    "2. Standard Deviation\n",
    "3. Range and IQR\n",
    "4. Which class was more consistent? (Hint: Lower CV = more consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class_a = [85, 90, 78, 92, 88, 76, 95, 89, 84, 91]\n",
    "class_b = [82, 95, 70, 98, 75, 88, 100, 65, 93, 84]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3.1\n",
    "class_a = np.array([85, 90, 78, 92, 88, 76, 95, 89, 84, 91])\n",
    "class_b = np.array([82, 95, 70, 98, 75, 88, 100, 65, 93, 84])\n",
    "\n",
    "def analyze_scores(scores, class_name):\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"  Mean: {np.mean(scores):.2f}\")\n",
    "    print(f\"  Median: {np.median(scores):.2f}\")\n",
    "    print(f\"  Standard Deviation: {np.std(scores, ddof=1):.2f}\")\n",
    "    print(f\"  Range: {np.max(scores) - np.min(scores)}\")\n",
    "    q1, q3 = np.percentile(scores, [25, 75])\n",
    "    print(f\"  IQR: {q3 - q1:.2f}\")\n",
    "    cv = (np.std(scores, ddof=1) / np.mean(scores)) * 100\n",
    "    print(f\"  Coefficient of Variation: {cv:.2f}%\")\n",
    "    return cv\n",
    "\n",
    "cv_a = analyze_scores(class_a, \"Class A\")\n",
    "cv_b = analyze_scores(class_b, \"Class B\")\n",
    "\n",
    "print(f\"\\nConclusion: {'Class A' if cv_a < cv_b else 'Class B'} performed more consistently.\")\n",
    "print(f\"(Lower CV indicates less variability relative to the mean)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Probability Basics\n",
    "---\n",
    "\n",
    "## What is Probability?\n",
    "\n",
    "Probability is a measure of the likelihood that an event will occur. It's expressed as a number between 0 (impossible) and 1 (certain).\n",
    "\n",
    "### Key Probability Concepts\n",
    "\n",
    "- **Experiment**: A process that produces an outcome (e.g., rolling a die)\n",
    "- **Sample Space**: All possible outcomes (e.g., {1, 2, 3, 4, 5, 6})\n",
    "- **Event**: A subset of the sample space (e.g., rolling an even number)\n",
    "- **Probability**: P(Event) = Number of favorable outcomes / Total possible outcomes\n",
    "\n",
    "### Why This Matters in Data Science\n",
    "\n",
    "Probability forms the foundation of:\n",
    "- Statistical inference and hypothesis testing\n",
    "- Machine learning algorithms (especially Bayesian methods)\n",
    "- Risk assessment and decision making\n",
    "- Understanding uncertainty in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Basic probability calculations\n",
    "\n",
    "# Rolling a fair six-sided die\n",
    "sample_space = [1, 2, 3, 4, 5, 6]\n",
    "total_outcomes = len(sample_space)\n",
    "\n",
    "# P(rolling a 4)\n",
    "favorable_4 = [x for x in sample_space if x == 4]\n",
    "p_four = len(favorable_4) / total_outcomes\n",
    "print(f\"P(rolling a 4) = {p_four:.4f} or {p_four:.2%}\")\n",
    "\n",
    "# P(rolling an even number)\n",
    "favorable_even = [x for x in sample_space if x % 2 == 0]\n",
    "p_even = len(favorable_even) / total_outcomes\n",
    "print(f\"P(rolling an even number) = {p_even:.4f} or {p_even:.2%}\")\n",
    "\n",
    "# P(rolling greater than 4)\n",
    "favorable_gt4 = [x for x in sample_space if x > 4]\n",
    "p_gt4 = len(favorable_gt4) / total_outcomes\n",
    "print(f\"P(rolling > 4) = {p_gt4:.4f} or {p_gt4:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complement rule: P(not A) = 1 - P(A)\n",
    "p_not_four = 1 - p_four\n",
    "print(f\"P(NOT rolling a 4) = {p_not_four:.4f}\")\n",
    "\n",
    "# Verify with simulation\n",
    "np.random.seed(42)\n",
    "rolls = np.random.randint(1, 7, size=10000)\n",
    "\n",
    "simulated_p_four = (rolls == 4).mean()\n",
    "simulated_p_even = (rolls % 2 == 0).mean()\n",
    "\n",
    "print(f\"\\nSimulated probabilities (10,000 rolls):\")\n",
    "print(f\"  P(4): {simulated_p_four:.4f} (theoretical: {p_four:.4f})\")\n",
    "print(f\"  P(even): {simulated_p_even:.4f} (theoretical: {p_even:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Probability: P(A|B) = P(A and B) / P(B)\n",
    "# Probability of A given that B has occurred\n",
    "\n",
    "# Example: Using our salary data\n",
    "# What's the probability that an employee earns > $100K given they're in Engineering?\n",
    "\n",
    "engineering_employees = salaries_df[salaries_df['department'] == 'Engineering']\n",
    "high_earners_in_eng = engineering_employees[engineering_employees['salary'] > 100000]\n",
    "\n",
    "p_high_given_eng = len(high_earners_in_eng) / len(engineering_employees)\n",
    "print(f\"P(Salary > $100K | Engineering) = {p_high_given_eng:.4f} or {p_high_given_eng:.2%}\")\n",
    "\n",
    "# Compare with overall probability of earning > $100K\n",
    "p_high_overall = (salaries_df['salary'] > 100000).mean()\n",
    "print(f\"P(Salary > $100K | Any department) = {p_high_overall:.4f} or {p_high_overall:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Events: P(A and B) = P(A) * P(B)\n",
    "# Events are independent if occurrence of one doesn't affect the other\n",
    "\n",
    "# Example: Flipping two coins\n",
    "p_heads = 0.5\n",
    "p_two_heads = p_heads * p_heads\n",
    "print(f\"P(two heads in a row) = {p_two_heads:.4f}\")\n",
    "\n",
    "# Verify with simulation\n",
    "np.random.seed(42)\n",
    "flips = np.random.choice(['H', 'T'], size=(10000, 2))\n",
    "two_heads = ((flips[:, 0] == 'H') & (flips[:, 1] == 'H')).mean()\n",
    "print(f\"Simulated P(two heads) = {two_heads:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutually Exclusive Events: P(A or B) = P(A) + P(B)\n",
    "# Events that cannot occur at the same time\n",
    "\n",
    "# Example: Rolling a 1 OR rolling a 6\n",
    "p_one = 1/6\n",
    "p_six = 1/6\n",
    "p_one_or_six = p_one + p_six\n",
    "print(f\"P(rolling 1 OR 6) = {p_one_or_six:.4f}\")\n",
    "\n",
    "# Non-mutually exclusive: P(A or B) = P(A) + P(B) - P(A and B)\n",
    "# Example: P(even OR greater than 4)\n",
    "# Even: {2, 4, 6}, Greater than 4: {5, 6}\n",
    "# Overlap: {6}\n",
    "\n",
    "p_even = 3/6\n",
    "p_gt4 = 2/6\n",
    "p_even_and_gt4 = 1/6  # Just 6\n",
    "p_even_or_gt4 = p_even + p_gt4 - p_even_and_gt4\n",
    "print(f\"P(even OR > 4) = {p_even_or_gt4:.4f}\")\n",
    "print(f\"  (Events {2, 4, 5, 6} = 4 outcomes out of 6)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: Probability Distributions\n",
    "---\n",
    "\n",
    "## What is a Probability Distribution?\n",
    "\n",
    "A probability distribution describes how probabilities are distributed over the values of a random variable. There are two main types:\n",
    "\n",
    "1. **Discrete Distributions** - For countable outcomes (integers)\n",
    "2. **Continuous Distributions** - For continuous outcomes (any real number)\n",
    "\n",
    "### Common Distributions in Data Science\n",
    "\n",
    "| Distribution | Type | Use Case |\n",
    "|--------------|------|----------|\n",
    "| Binomial | Discrete | Number of successes in n trials |\n",
    "| Poisson | Discrete | Count of events in a time period |\n",
    "| Normal | Continuous | Many natural phenomena |\n",
    "| Uniform | Both | Equal probability for all values |\n",
    "| Exponential | Continuous | Time between events |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "# Normal Distribution\n",
    "stats.norm.pdf(x, loc=mean, scale=std)  # Probability density function\n",
    "stats.norm.cdf(x, loc=mean, scale=std)  # Cumulative distribution function\n",
    "stats.norm.ppf(q, loc=mean, scale=std)  # Percent point function (inverse CDF)\n",
    "stats.norm.rvs(loc=mean, scale=std, size=n)  # Random samples\n",
    "\n",
    "# Binomial Distribution\n",
    "stats.binom.pmf(k, n, p)  # Probability mass function\n",
    "stats.binom.cdf(k, n, p)  # Cumulative distribution function\n",
    "\n",
    "# Poisson Distribution\n",
    "stats.poisson.pmf(k, mu)  # Probability mass function\n",
    "stats.poisson.cdf(k, mu)  # Cumulative distribution function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal (Gaussian) Distribution\n",
    "# The most important distribution in statistics\n",
    "\n",
    "# Create a normal distribution with mean=0, std=1 (standard normal)\n",
    "x = np.linspace(-4, 4, 100)\n",
    "standard_normal = stats.norm.pdf(x, loc=0, scale=1)\n",
    "\n",
    "# Different means and standard deviations\n",
    "normal_1 = stats.norm.pdf(x, loc=0, scale=1)\n",
    "normal_2 = stats.norm.pdf(x, loc=0, scale=2)  # Wider spread\n",
    "normal_3 = stats.norm.pdf(x, loc=2, scale=1)  # Shifted mean\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, normal_1, label='mean=0, std=1', linewidth=2)\n",
    "plt.plot(x, normal_2, label='mean=0, std=2', linewidth=2)\n",
    "plt.plot(x, normal_3, label='mean=2, std=1', linewidth=2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Normal Distributions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the normal distribution for probability calculations\n",
    "# Example: IQ scores are normally distributed with mean=100, std=15\n",
    "\n",
    "mean_iq = 100\n",
    "std_iq = 15\n",
    "\n",
    "# What percentage of people have IQ above 130?\n",
    "p_above_130 = 1 - stats.norm.cdf(130, loc=mean_iq, scale=std_iq)\n",
    "print(f\"P(IQ > 130) = {p_above_130:.4f} or {p_above_130:.2%}\")\n",
    "\n",
    "# What percentage of people have IQ between 85 and 115?\n",
    "p_between = stats.norm.cdf(115, loc=mean_iq, scale=std_iq) - stats.norm.cdf(85, loc=mean_iq, scale=std_iq)\n",
    "print(f\"P(85 < IQ < 115) = {p_between:.4f} or {p_between:.2%}\")\n",
    "\n",
    "# What IQ score is at the 95th percentile?\n",
    "iq_95th = stats.norm.ppf(0.95, loc=mean_iq, scale=std_iq)\n",
    "print(f\"95th percentile IQ = {iq_95th:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial Distribution\n",
    "# Models the number of successes in n independent trials with probability p\n",
    "\n",
    "# Example: A website has a 5% conversion rate. \n",
    "# If 100 people visit, what's the probability of exactly 7 conversions?\n",
    "\n",
    "n_visitors = 100\n",
    "p_convert = 0.05\n",
    "\n",
    "# P(exactly 7 conversions)\n",
    "p_exactly_7 = stats.binom.pmf(7, n_visitors, p_convert)\n",
    "print(f\"P(exactly 7 conversions) = {p_exactly_7:.4f}\")\n",
    "\n",
    "# P(at most 3 conversions)\n",
    "p_at_most_3 = stats.binom.cdf(3, n_visitors, p_convert)\n",
    "print(f\"P(at most 3 conversions) = {p_at_most_3:.4f}\")\n",
    "\n",
    "# P(at least 10 conversions)\n",
    "p_at_least_10 = 1 - stats.binom.cdf(9, n_visitors, p_convert)\n",
    "print(f\"P(at least 10 conversions) = {p_at_least_10:.4f}\")\n",
    "\n",
    "# Expected value (mean) and standard deviation\n",
    "expected = n_visitors * p_convert\n",
    "std = np.sqrt(n_visitors * p_convert * (1 - p_convert))\n",
    "print(f\"\\nExpected conversions: {expected:.2f}\")\n",
    "print(f\"Standard deviation: {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the binomial distribution\n",
    "k_values = np.arange(0, 20)\n",
    "probabilities = stats.binom.pmf(k_values, n_visitors, p_convert)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(k_values, probabilities, edgecolor='black')\n",
    "plt.axvline(expected, color='red', linestyle='--', linewidth=2, label=f'Expected: {expected}')\n",
    "plt.xlabel('Number of Conversions')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Binomial Distribution (n={n_visitors}, p={p_convert})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson Distribution\n",
    "# Models the number of events occurring in a fixed interval when events happen at a constant rate\n",
    "\n",
    "# Example: A call center receives an average of 4 calls per minute\n",
    "# What's the probability of receiving exactly 6 calls in a minute?\n",
    "\n",
    "lambda_rate = 4  # average calls per minute\n",
    "\n",
    "p_exactly_6 = stats.poisson.pmf(6, lambda_rate)\n",
    "print(f\"P(exactly 6 calls) = {p_exactly_6:.4f}\")\n",
    "\n",
    "# P(no calls in a minute)\n",
    "p_zero = stats.poisson.pmf(0, lambda_rate)\n",
    "print(f\"P(0 calls) = {p_zero:.4f}\")\n",
    "\n",
    "# P(more than 7 calls)\n",
    "p_more_than_7 = 1 - stats.poisson.cdf(7, lambda_rate)\n",
    "print(f\"P(more than 7 calls) = {p_more_than_7:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Normal\n",
    "x = np.linspace(-4, 4, 100)\n",
    "axes[0].plot(x, stats.norm.pdf(x), linewidth=2)\n",
    "axes[0].fill_between(x, stats.norm.pdf(x), alpha=0.3)\n",
    "axes[0].set_title('Normal Distribution\\n(Continuous)')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('Density')\n",
    "\n",
    "# Binomial\n",
    "k = np.arange(0, 21)\n",
    "axes[1].bar(k, stats.binom.pmf(k, 20, 0.5), edgecolor='black')\n",
    "axes[1].set_title('Binomial Distribution\\n(n=20, p=0.5)')\n",
    "axes[1].set_xlabel('k (successes)')\n",
    "axes[1].set_ylabel('Probability')\n",
    "\n",
    "# Poisson\n",
    "k = np.arange(0, 15)\n",
    "axes[2].bar(k, stats.poisson.pmf(k, 5), edgecolor='black')\n",
    "axes[2].set_title('Poisson Distribution\\n(lambda=5)')\n",
    "axes[2].set_xlabel('k (events)')\n",
    "axes[2].set_ylabel('Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Hypothesis Testing Fundamentals\n",
    "---\n",
    "\n",
    "## What is Hypothesis Testing?\n",
    "\n",
    "Hypothesis testing is a statistical method for making decisions based on data. It helps us determine whether observed differences or effects are statistically significant or just due to random chance.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Null Hypothesis (H0)**: The default assumption (usually \"no effect\" or \"no difference\")\n",
    "2. **Alternative Hypothesis (H1 or Ha)**: What we're trying to prove\n",
    "3. **Test Statistic**: A value calculated from the data\n",
    "4. **P-value**: Probability of observing results as extreme as ours, assuming H0 is true\n",
    "5. **Significance Level (alpha)**: Threshold for rejecting H0 (commonly 0.05)\n",
    "\n",
    "### The Hypothesis Testing Process\n",
    "\n",
    "1. State the hypotheses (H0 and H1)\n",
    "2. Choose significance level (alpha)\n",
    "3. Collect data and calculate test statistic\n",
    "4. Calculate p-value\n",
    "5. Make a decision: Reject H0 if p-value < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "# One-sample t-test (compare sample mean to known value)\n",
    "t_stat, p_value = stats.ttest_1samp(sample_data, population_mean)\n",
    "\n",
    "# Two-sample t-test (compare means of two groups)\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "\n",
    "# Paired t-test (compare before/after measurements)\n",
    "t_stat, p_value = stats.ttest_rel(before, after)\n",
    "\n",
    "# Chi-square test (for categorical data)\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Mann-Whitney U test (non-parametric alternative to t-test)\n",
    "stat, p_value = stats.mannwhitneyu(group1, group2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: One-sample t-test\n",
    "# A company claims their batteries last 500 hours on average.\n",
    "# We test 30 batteries and want to know if this claim is accurate.\n",
    "\n",
    "np.random.seed(42)\n",
    "# Simulate battery life data (true mean is 485 hours)\n",
    "battery_life = np.random.normal(485, 30, 30)\n",
    "\n",
    "print(\"Battery Life Test\")\n",
    "print(f\"Sample size: {len(battery_life)}\")\n",
    "print(f\"Sample mean: {battery_life.mean():.2f} hours\")\n",
    "print(f\"Sample std: {battery_life.std():.2f} hours\")\n",
    "\n",
    "# Hypothesis test\n",
    "# H0: mu = 500 (company's claim is true)\n",
    "# H1: mu != 500 (company's claim is false)\n",
    "\n",
    "claimed_mean = 500\n",
    "t_stat, p_value = stats.ttest_1samp(battery_life, claimed_mean)\n",
    "\n",
    "print(f\"\\nHypothesis Test Results:\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nConclusion: Reject H0 (p < {alpha})\")\n",
    "    print(\"The evidence suggests the batteries do NOT last 500 hours on average.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Fail to reject H0 (p >= {alpha})\")\n",
    "    print(\"There is not enough evidence to reject the company's claim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Two-sample t-test\n",
    "# Compare salaries between Engineering and Marketing departments\n",
    "\n",
    "engineering = salaries_df[salaries_df['department'] == 'Engineering']['salary']\n",
    "marketing = salaries_df[salaries_df['department'] == 'Marketing']['salary']\n",
    "\n",
    "print(\"Engineering vs Marketing Salary Comparison\")\n",
    "print(f\"Engineering: n={len(engineering)}, mean=${engineering.mean():,.2f}\")\n",
    "print(f\"Marketing: n={len(marketing)}, mean=${marketing.mean():,.2f}\")\n",
    "\n",
    "# Hypothesis test\n",
    "# H0: There is no difference in mean salaries between departments\n",
    "# H1: There is a difference in mean salaries\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(engineering, marketing)\n",
    "\n",
    "print(f\"\\nTwo-sample t-test Results:\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.6f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nConclusion: Reject H0 (p < {alpha})\")\n",
    "    print(\"There is a statistically significant difference in salaries.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Fail to reject H0 (p >= {alpha})\")\n",
    "    print(\"No significant difference detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create side-by-side histograms\n",
    "ax.hist(engineering, bins=20, alpha=0.5, label=f'Engineering (mean=${engineering.mean():,.0f})')\n",
    "ax.hist(marketing, bins=20, alpha=0.5, label=f'Marketing (mean=${marketing.mean():,.0f})')\n",
    "\n",
    "ax.axvline(engineering.mean(), color='blue', linestyle='--', linewidth=2)\n",
    "ax.axvline(marketing.mean(), color='orange', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Salary ($)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Salary Distribution Comparison (p-value = {p_value:.6f})')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Paired t-test\n",
    "# Compare employee productivity before and after a training program\n",
    "\n",
    "np.random.seed(42)\n",
    "n_employees = 25\n",
    "\n",
    "# Productivity scores (tasks completed per day)\n",
    "before_training = np.random.normal(20, 5, n_employees)\n",
    "# After training, there's a small improvement (+ noise)\n",
    "after_training = before_training + np.random.normal(2, 3, n_employees)\n",
    "\n",
    "print(\"Productivity Before vs After Training\")\n",
    "print(f\"Before: mean = {before_training.mean():.2f} tasks/day\")\n",
    "print(f\"After: mean = {after_training.mean():.2f} tasks/day\")\n",
    "print(f\"Mean improvement: {(after_training - before_training).mean():.2f} tasks/day\")\n",
    "\n",
    "# Paired t-test (same subjects measured twice)\n",
    "# H0: No difference before and after training\n",
    "# H1: There is a difference\n",
    "\n",
    "t_stat, p_value = stats.ttest_rel(before_training, after_training)\n",
    "\n",
    "print(f\"\\nPaired t-test Results:\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nConclusion: The training had a statistically significant effect.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: No significant effect detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Type I and Type II Errors\n",
    "\n",
    "print(\"Hypothesis Testing Errors:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"                    | H0 True        | H0 False       \")\n",
    "print(\"-\" * 60)\n",
    "print(\"Reject H0           | Type I Error   | Correct!       \")\n",
    "print(\"                    | (False Pos)    | (True Pos)     \")\n",
    "print(\"-\" * 60)\n",
    "print(\"Fail to Reject H0   | Correct!       | Type II Error  \")\n",
    "print(\"                    | (True Neg)     | (False Neg)    \")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nType I Error (alpha): Probability of rejecting H0 when it's true\")\n",
    "print(\"Type II Error (beta): Probability of failing to reject H0 when it's false\")\n",
    "print(\"Power = 1 - beta: Probability of correctly rejecting a false H0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 6.1\n",
    "\n",
    "**Task:** A coffee shop claims their medium coffee contains 12 oz on average. You suspect they might be under-filling cups. You measure 20 cups and get the following data:\n",
    "\n",
    "```python\n",
    "coffee_amounts = [11.8, 12.1, 11.5, 11.9, 12.0, 11.7, 11.6, 12.2, 11.4, 11.8,\n",
    "                  11.9, 12.0, 11.5, 11.7, 11.8, 12.1, 11.6, 11.9, 11.7, 11.8]\n",
    "```\n",
    "\n",
    "1. State the null and alternative hypotheses\n",
    "2. Perform a one-sample t-test\n",
    "3. At alpha = 0.05, what is your conclusion?\n",
    "4. Calculate the 95% confidence interval for the true mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "coffee_amounts = [11.8, 12.1, 11.5, 11.9, 12.0, 11.7, 11.6, 12.2, 11.4, 11.8,\n",
    "                  11.9, 12.0, 11.5, 11.7, 11.8, 12.1, 11.6, 11.9, 11.7, 11.8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 6.1\n",
    "coffee_amounts = np.array([11.8, 12.1, 11.5, 11.9, 12.0, 11.7, 11.6, 12.2, 11.4, 11.8,\n",
    "                           11.9, 12.0, 11.5, 11.7, 11.8, 12.1, 11.6, 11.9, 11.7, 11.8])\n",
    "\n",
    "print(\"Coffee Shop Under-filling Test\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. State hypotheses\n",
    "print(\"\\n1. Hypotheses:\")\n",
    "print(\"   H0: mu = 12 oz (coffee shop fills correctly)\")\n",
    "print(\"   H1: mu < 12 oz (coffee shop under-fills)\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSample statistics:\")\n",
    "print(f\"   n = {len(coffee_amounts)}\")\n",
    "print(f\"   Sample mean = {coffee_amounts.mean():.3f} oz\")\n",
    "print(f\"   Sample std = {coffee_amounts.std(ddof=1):.3f} oz\")\n",
    "\n",
    "# 2. Perform t-test\n",
    "claimed_mean = 12\n",
    "t_stat, p_value_two_sided = stats.ttest_1samp(coffee_amounts, claimed_mean)\n",
    "\n",
    "# For one-sided test (H1: mu < 12), divide p-value by 2\n",
    "# Only if t-statistic is negative (sample mean < claimed mean)\n",
    "p_value_one_sided = p_value_two_sided / 2 if t_stat < 0 else 1 - p_value_two_sided / 2\n",
    "\n",
    "print(f\"\\n2. Test Results:\")\n",
    "print(f\"   t-statistic: {t_stat:.4f}\")\n",
    "print(f\"   p-value (one-sided): {p_value_one_sided:.4f}\")\n",
    "\n",
    "# 3. Conclusion\n",
    "alpha = 0.05\n",
    "print(f\"\\n3. Conclusion (alpha = {alpha}):\")\n",
    "if p_value_one_sided < alpha:\n",
    "    print(f\"   Reject H0 (p = {p_value_one_sided:.4f} < {alpha})\")\n",
    "    print(\"   Evidence suggests the coffee shop is under-filling cups.\")\n",
    "else:\n",
    "    print(f\"   Fail to reject H0 (p = {p_value_one_sided:.4f} >= {alpha})\")\n",
    "    print(\"   Not enough evidence to conclude under-filling.\")\n",
    "\n",
    "# 4. Confidence interval\n",
    "confidence_level = 0.95\n",
    "ci = stats.t.interval(confidence_level, \n",
    "                      df=len(coffee_amounts)-1,\n",
    "                      loc=coffee_amounts.mean(),\n",
    "                      scale=stats.sem(coffee_amounts))\n",
    "\n",
    "print(f\"\\n4. 95% Confidence Interval:\")\n",
    "print(f\"   ({ci[0]:.3f}, {ci[1]:.3f}) oz\")\n",
    "print(f\"   Note: 12 oz {'is NOT' if ci[1] < 12 else 'IS'} contained in the interval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 7: Correlation and Covariance\n",
    "---\n",
    "\n",
    "## What are Correlation and Covariance?\n",
    "\n",
    "Both measure the relationship between two variables, but they differ in interpretation:\n",
    "\n",
    "**Covariance**: Measures how two variables change together\n",
    "- Positive: Variables move in the same direction\n",
    "- Negative: Variables move in opposite directions\n",
    "- Problem: Scale-dependent, hard to interpret\n",
    "\n",
    "**Correlation (Pearson's r)**: Standardized covariance\n",
    "- Range: -1 to +1\n",
    "- +1: Perfect positive linear relationship\n",
    "- -1: Perfect negative linear relationship\n",
    "- 0: No linear relationship\n",
    "\n",
    "### Interpretation Guidelines\n",
    "\n",
    "| Correlation | Strength |\n",
    "|-------------|----------|\n",
    "| 0.0 - 0.2 | Very weak |\n",
    "| 0.2 - 0.4 | Weak |\n",
    "| 0.4 - 0.6 | Moderate |\n",
    "| 0.6 - 0.8 | Strong |\n",
    "| 0.8 - 1.0 | Very strong |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "# Covariance\n",
    "cov_matrix = np.cov(x, y)           # Returns 2x2 covariance matrix\n",
    "cov_value = np.cov(x, y)[0, 1]      # Extract covariance\n",
    "\n",
    "# Correlation\n",
    "corr_matrix = np.corrcoef(x, y)     # Returns 2x2 correlation matrix\n",
    "corr_value = np.corrcoef(x, y)[0, 1]  # Extract correlation\n",
    "\n",
    "# Using pandas\n",
    "df['col1'].cov(df['col2'])          # Covariance between two columns\n",
    "df['col1'].corr(df['col2'])         # Correlation between two columns\n",
    "df.corr()                           # Correlation matrix for all columns\n",
    "\n",
    "# Statistical test for correlation (with p-value)\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "corr, p_value = pearsonr(x, y)      # Pearson correlation\n",
    "corr, p_value = spearmanr(x, y)     # Spearman correlation (rank-based)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data to explore correlation\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Create variables with different relationships\n",
    "x = np.random.normal(50, 10, n)\n",
    "\n",
    "# Strong positive correlation\n",
    "y_positive = 2 * x + np.random.normal(0, 5, n)\n",
    "\n",
    "# Strong negative correlation\n",
    "y_negative = -1.5 * x + 150 + np.random.normal(0, 5, n)\n",
    "\n",
    "# No correlation\n",
    "y_none = np.random.normal(50, 10, n)\n",
    "\n",
    "# Non-linear relationship (correlation may miss this!)\n",
    "y_nonlinear = (x - 50) ** 2 + np.random.normal(0, 30, n)\n",
    "\n",
    "# Calculate correlations\n",
    "print(\"Pearson Correlations:\")\n",
    "print(f\"  Positive relationship: r = {np.corrcoef(x, y_positive)[0,1]:.3f}\")\n",
    "print(f\"  Negative relationship: r = {np.corrcoef(x, y_negative)[0,1]:.3f}\")\n",
    "print(f\"  No relationship: r = {np.corrcoef(x, y_none)[0,1]:.3f}\")\n",
    "print(f\"  Non-linear relationship: r = {np.corrcoef(x, y_nonlinear)[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different correlation patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "datasets = [\n",
    "    (x, y_positive, 'Strong Positive'),\n",
    "    (x, y_negative, 'Strong Negative'),\n",
    "    (x, y_none, 'No Correlation'),\n",
    "    (x, y_nonlinear, 'Non-linear')\n",
    "]\n",
    "\n",
    "for ax, (data_x, data_y, title) in zip(axes.flat, datasets):\n",
    "    ax.scatter(data_x, data_y, alpha=0.5)\n",
    "    corr = np.corrcoef(data_x, data_y)[0, 1]\n",
    "    ax.set_title(f'{title}\\nr = {corr:.3f}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    \n",
    "    # Add trend line for linear relationships\n",
    "    if title != 'Non-linear':\n",
    "        z = np.polyfit(data_x, data_y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(sorted(data_x), p(sorted(data_x)), \"r--\", alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with significance testing\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "print(\"Statistical Tests for Correlation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test positive relationship\n",
    "r, p_value = pearsonr(x, y_positive)\n",
    "print(f\"\\nPositive relationship:\")\n",
    "print(f\"  Pearson r = {r:.4f}\")\n",
    "print(f\"  p-value = {p_value:.2e}\")\n",
    "print(f\"  Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Test no relationship\n",
    "r, p_value = pearsonr(x, y_none)\n",
    "print(f\"\\nNo relationship:\")\n",
    "print(f\"  Pearson r = {r:.4f}\")\n",
    "print(f\"  p-value = {p_value:.4f}\")\n",
    "print(f\"  Significant: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman correlation - for non-linear monotonic relationships\n",
    "# Based on ranks, not actual values\n",
    "\n",
    "# Create a monotonic but non-linear relationship\n",
    "x_mono = np.arange(1, 101)\n",
    "y_mono = np.log(x_mono) + np.random.normal(0, 0.2, 100)  # Logarithmic relationship\n",
    "\n",
    "pearson_r, _ = pearsonr(x_mono, y_mono)\n",
    "spearman_r, _ = spearmanr(x_mono, y_mono)\n",
    "\n",
    "print(f\"Logarithmic relationship (y = log(x) + noise):\")\n",
    "print(f\"  Pearson r = {pearson_r:.4f}\")\n",
    "print(f\"  Spearman r = {spearman_r:.4f}\")\n",
    "print(f\"\\nSpearman is higher because it captures monotonic relationships\")\n",
    "print(\"even when they're not perfectly linear.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world example: Correlation matrix with salary data\n",
    "# Let's create a more complete employee dataset\n",
    "\n",
    "np.random.seed(42)\n",
    "n_emp = 200\n",
    "\n",
    "# Generate correlated features\n",
    "years_experience = np.random.uniform(0, 20, n_emp)\n",
    "education_years = np.random.uniform(12, 22, n_emp)  # 12 = high school, 22 = PhD\n",
    "\n",
    "# Salary correlated with experience and education\n",
    "base_salary = 40000\n",
    "salary = (base_salary + \n",
    "          years_experience * 3000 + \n",
    "          education_years * 2000 + \n",
    "          np.random.normal(0, 8000, n_emp))\n",
    "\n",
    "# Performance somewhat correlated with experience\n",
    "performance_score = 3 + years_experience * 0.1 + np.random.normal(0, 1, n_emp)\n",
    "performance_score = np.clip(performance_score, 1, 5)\n",
    "\n",
    "# Age correlated with experience (logically)\n",
    "age = 22 + years_experience + np.random.normal(0, 3, n_emp)\n",
    "\n",
    "employee_data = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'years_experience': years_experience,\n",
    "    'education_years': education_years,\n",
    "    'salary': salary,\n",
    "    'performance_score': performance_score\n",
    "})\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = employee_data.corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix as heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            vmin=-1, vmax=1, fmt='.2f', square=True)\n",
    "plt.title('Employee Data Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Correlation does not imply causation!\n",
    "# Example of spurious correlation\n",
    "\n",
    "np.random.seed(42)\n",
    "years = np.arange(2000, 2020)\n",
    "\n",
    "# Two completely unrelated trends that both increase over time\n",
    "ice_cream_sales = 1000 + 50 * (years - 2000) + np.random.normal(0, 30, 20)\n",
    "drowning_incidents = 100 + 5 * (years - 2000) + np.random.normal(0, 10, 20)\n",
    "\n",
    "corr = np.corrcoef(ice_cream_sales, drowning_incidents)[0, 1]\n",
    "print(f\"Correlation between ice cream sales and drowning incidents: r = {corr:.3f}\")\n",
    "print(\"\\nThis is a SPURIOUS correlation! Both are actually caused by a third\")\n",
    "print(\"variable (summer/hot weather) that affects both independently.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 8: A/B Testing Basics\n",
    "---\n",
    "\n",
    "## What is A/B Testing?\n",
    "\n",
    "A/B testing (also called split testing) is a method of comparing two versions of something to determine which performs better. It's widely used in:\n",
    "\n",
    "- Web design (button colors, layouts)\n",
    "- Marketing (email subject lines, ads)\n",
    "- Product development (features, pricing)\n",
    "\n",
    "### The A/B Testing Process\n",
    "\n",
    "1. **Define the goal**: What metric are you trying to improve?\n",
    "2. **Create variants**: Control (A) and Treatment (B)\n",
    "3. **Determine sample size**: How many observations needed?\n",
    "4. **Randomly assign users**: Ensure groups are comparable\n",
    "5. **Run the experiment**: Collect data\n",
    "6. **Analyze results**: Is the difference statistically significant?\n",
    "7. **Make a decision**: Implement winner or iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: A/B Test for Website Conversion Rate\n",
    "# A company wants to test if a new button color (green) increases conversions\n",
    "# compared to the original (blue)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate data\n",
    "n_control = 1000  # Users who saw blue button\n",
    "n_treatment = 1000  # Users who saw green button\n",
    "\n",
    "# True conversion rates (unknown in practice)\n",
    "true_rate_control = 0.10  # 10% conversion for blue\n",
    "true_rate_treatment = 0.12  # 12% conversion for green\n",
    "\n",
    "# Simulate conversions (1 = converted, 0 = didn't convert)\n",
    "control_conversions = np.random.binomial(1, true_rate_control, n_control)\n",
    "treatment_conversions = np.random.binomial(1, true_rate_treatment, n_treatment)\n",
    "\n",
    "# Calculate observed conversion rates\n",
    "control_rate = control_conversions.mean()\n",
    "treatment_rate = treatment_conversions.mean()\n",
    "\n",
    "print(\"A/B Test: Button Color Experiment\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nControl (Blue Button):\")\n",
    "print(f\"  Sample size: {n_control}\")\n",
    "print(f\"  Conversions: {control_conversions.sum()}\")\n",
    "print(f\"  Conversion rate: {control_rate:.2%}\")\n",
    "\n",
    "print(f\"\\nTreatment (Green Button):\")\n",
    "print(f\"  Sample size: {n_treatment}\")\n",
    "print(f\"  Conversions: {treatment_conversions.sum()}\")\n",
    "print(f\"  Conversion rate: {treatment_rate:.2%}\")\n",
    "\n",
    "print(f\"\\nAbsolute Difference: {treatment_rate - control_rate:.2%}\")\n",
    "print(f\"Relative Lift: {((treatment_rate - control_rate) / control_rate) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test for A/B test (proportions)\n",
    "from scipy.stats import chi2_contingency, norm\n",
    "\n",
    "# Create contingency table\n",
    "contingency_table = np.array([\n",
    "    [control_conversions.sum(), n_control - control_conversions.sum()],\n",
    "    [treatment_conversions.sum(), n_treatment - treatment_conversions.sum()]\n",
    "])\n",
    "\n",
    "print(\"Contingency Table:\")\n",
    "print(pd.DataFrame(contingency_table, \n",
    "                   index=['Control', 'Treatment'],\n",
    "                   columns=['Converted', 'Not Converted']))\n",
    "\n",
    "# Chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"\\nChi-square Test Results:\")\n",
    "print(f\"  Chi-square statistic: {chi2:.4f}\")\n",
    "print(f\"  Degrees of freedom: {dof}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nConclusion: The difference IS statistically significant (p < {alpha})\")\n",
    "    print(\"The green button appears to increase conversions.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: The difference is NOT statistically significant (p >= {alpha})\")\n",
    "    print(\"We cannot conclude that the button color affects conversions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-test for proportions (alternative approach)\n",
    "# This is often used for A/B tests with binary outcomes\n",
    "\n",
    "def z_test_proportions(successes_a, n_a, successes_b, n_b):\n",
    "    \"\"\"Two-proportion z-test.\"\"\"\n",
    "    p_a = successes_a / n_a\n",
    "    p_b = successes_b / n_b\n",
    "    \n",
    "    # Pooled proportion\n",
    "    p_pooled = (successes_a + successes_b) / (n_a + n_b)\n",
    "    \n",
    "    # Standard error\n",
    "    se = np.sqrt(p_pooled * (1 - p_pooled) * (1/n_a + 1/n_b))\n",
    "    \n",
    "    # Z-statistic\n",
    "    z = (p_b - p_a) / se\n",
    "    \n",
    "    # P-value (two-tailed)\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z)))\n",
    "    \n",
    "    return z, p_value, p_a, p_b\n",
    "\n",
    "z_stat, p_val, p_ctrl, p_treat = z_test_proportions(\n",
    "    control_conversions.sum(), n_control,\n",
    "    treatment_conversions.sum(), n_treatment\n",
    ")\n",
    "\n",
    "print(\"Z-Test for Proportions:\")\n",
    "print(f\"  Control proportion: {p_ctrl:.4f}\")\n",
    "print(f\"  Treatment proportion: {p_treat:.4f}\")\n",
    "print(f\"  Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"  p-value: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Size Calculation\n",
    "# How many samples do we need to detect a given effect?\n",
    "\n",
    "def calculate_sample_size(baseline_rate, minimum_detectable_effect, alpha=0.05, power=0.80):\n",
    "    \"\"\"\n",
    "    Calculate required sample size for A/B test.\n",
    "    \n",
    "    Parameters:\n",
    "    - baseline_rate: Current conversion rate (e.g., 0.10 for 10%)\n",
    "    - minimum_detectable_effect: Relative change to detect (e.g., 0.20 for 20% lift)\n",
    "    - alpha: Significance level (Type I error rate)\n",
    "    - power: Statistical power (1 - Type II error rate)\n",
    "    \"\"\"\n",
    "    # New rate after effect\n",
    "    new_rate = baseline_rate * (1 + minimum_detectable_effect)\n",
    "    \n",
    "    # Z-scores\n",
    "    z_alpha = norm.ppf(1 - alpha/2)\n",
    "    z_beta = norm.ppf(power)\n",
    "    \n",
    "    # Pooled variance estimate\n",
    "    p_avg = (baseline_rate + new_rate) / 2\n",
    "    \n",
    "    # Sample size formula\n",
    "    numerator = (z_alpha * np.sqrt(2 * p_avg * (1 - p_avg)) + \n",
    "                 z_beta * np.sqrt(baseline_rate * (1 - baseline_rate) + \n",
    "                                  new_rate * (1 - new_rate))) ** 2\n",
    "    denominator = (new_rate - baseline_rate) ** 2\n",
    "    \n",
    "    n_per_group = numerator / denominator\n",
    "    \n",
    "    return int(np.ceil(n_per_group))\n",
    "\n",
    "# Example: Current conversion rate is 10%, want to detect 20% relative lift\n",
    "baseline = 0.10\n",
    "mde = 0.20  # 20% relative increase (from 10% to 12%)\n",
    "\n",
    "required_n = calculate_sample_size(baseline, mde)\n",
    "\n",
    "print(\"Sample Size Calculation\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Baseline conversion rate: {baseline:.1%}\")\n",
    "print(f\"Minimum detectable effect: {mde:.0%} relative lift\")\n",
    "print(f\"Target conversion rate: {baseline * (1 + mde):.1%}\")\n",
    "print(f\"Significance level (alpha): 0.05\")\n",
    "print(f\"Statistical power: 80%\")\n",
    "print(f\"\\nRequired sample size: {required_n:,} per group\")\n",
    "print(f\"Total required: {2 * required_n:,} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize A/B test results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of conversion rates\n",
    "groups = ['Control\\n(Blue)', 'Treatment\\n(Green)']\n",
    "rates = [control_rate, treatment_rate]\n",
    "colors = ['steelblue', 'forestgreen']\n",
    "\n",
    "bars = axes[0].bar(groups, rates, color=colors, edgecolor='black')\n",
    "axes[0].set_ylabel('Conversion Rate')\n",
    "axes[0].set_title('Conversion Rate by Group')\n",
    "axes[0].set_ylim(0, max(rates) * 1.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, rate in zip(bars, rates):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                 f'{rate:.2%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add confidence intervals\n",
    "def confidence_interval(successes, n, confidence=0.95):\n",
    "    p = successes / n\n",
    "    z = norm.ppf((1 + confidence) / 2)\n",
    "    margin = z * np.sqrt(p * (1 - p) / n)\n",
    "    return p - margin, p + margin\n",
    "\n",
    "ci_control = confidence_interval(control_conversions.sum(), n_control)\n",
    "ci_treatment = confidence_interval(treatment_conversions.sum(), n_treatment)\n",
    "\n",
    "# Error bars\n",
    "errors = [[rates[0] - ci_control[0], rates[1] - ci_treatment[0]],\n",
    "          [ci_control[1] - rates[0], ci_treatment[1] - rates[1]]]\n",
    "axes[0].errorbar([0, 1], rates, yerr=errors, fmt='none', color='black', capsize=5)\n",
    "\n",
    "# Distribution of possible outcomes (simulation)\n",
    "simulated_control = np.random.binomial(n_control, control_rate, 10000) / n_control\n",
    "simulated_treatment = np.random.binomial(n_treatment, treatment_rate, 10000) / n_treatment\n",
    "\n",
    "axes[1].hist(simulated_control, bins=50, alpha=0.5, label='Control', color='steelblue')\n",
    "axes[1].hist(simulated_treatment, bins=50, alpha=0.5, label='Treatment', color='forestgreen')\n",
    "axes[1].axvline(control_rate, color='steelblue', linestyle='--', linewidth=2)\n",
    "axes[1].axvline(treatment_rate, color='forestgreen', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Conversion Rate')\n",
    "axes[1].set_ylabel('Frequency (Simulations)')\n",
    "axes[1].set_title('Distribution of Possible Outcomes')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 8.1\n",
    "\n",
    "**Task:** An e-commerce company ran an A/B test on their checkout page. They tested a new \"simplified checkout\" (Treatment) against the original (Control). Here are the results:\n",
    "\n",
    "- **Control**: 5,000 visitors, 350 completed purchases\n",
    "- **Treatment**: 5,200 visitors, 390 completed purchases\n",
    "\n",
    "1. Calculate the conversion rate for each group\n",
    "2. Calculate the relative lift (% improvement)\n",
    "3. Perform a statistical test to determine if the difference is significant (alpha = 0.05)\n",
    "4. What is your recommendation to the company?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "control_visitors = 5000\n",
    "control_purchases = 350\n",
    "treatment_visitors = 5200\n",
    "treatment_purchases = 390\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 8.1\n",
    "control_visitors = 5000\n",
    "control_purchases = 350\n",
    "treatment_visitors = 5200\n",
    "treatment_purchases = 390\n",
    "\n",
    "print(\"E-commerce A/B Test Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Conversion rates\n",
    "control_rate = control_purchases / control_visitors\n",
    "treatment_rate = treatment_purchases / treatment_visitors\n",
    "\n",
    "print(f\"\\n1. Conversion Rates:\")\n",
    "print(f\"   Control: {control_rate:.4f} ({control_rate:.2%})\")\n",
    "print(f\"   Treatment: {treatment_rate:.4f} ({treatment_rate:.2%})\")\n",
    "\n",
    "# 2. Relative lift\n",
    "absolute_diff = treatment_rate - control_rate\n",
    "relative_lift = (treatment_rate - control_rate) / control_rate * 100\n",
    "\n",
    "print(f\"\\n2. Lift:\")\n",
    "print(f\"   Absolute difference: {absolute_diff:.4f} ({absolute_diff:.2%})\")\n",
    "print(f\"   Relative lift: {relative_lift:.2f}%\")\n",
    "\n",
    "# 3. Statistical test\n",
    "contingency_table = np.array([\n",
    "    [control_purchases, control_visitors - control_purchases],\n",
    "    [treatment_purchases, treatment_visitors - treatment_purchases]\n",
    "])\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"\\n3. Statistical Test (Chi-square):\")\n",
    "print(f\"   Chi-square statistic: {chi2:.4f}\")\n",
    "print(f\"   p-value: {p_value:.4f}\")\n",
    "print(f\"   Significant at alpha=0.05: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# 4. Recommendation\n",
    "print(f\"\\n4. Recommendation:\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"   The simplified checkout shows a statistically significant\")\n",
    "    print(f\"   improvement of {relative_lift:.1f}% in conversion rate.\")\n",
    "    print(f\"   RECOMMEND: Implement the new checkout for all users.\")\n",
    "else:\n",
    "    print(f\"   While there appears to be a {relative_lift:.1f}% improvement,\")\n",
    "    print(f\"   this difference is NOT statistically significant (p={p_value:.3f}).\")\n",
    "    print(f\"   RECOMMEND: Continue testing with more data, or consider other factors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Module Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### Descriptive Statistics\n",
    "- Descriptive statistics summarize data through measures of central tendency, dispersion, and shape\n",
    "- Use pandas `.describe()` for a quick overview of numerical data\n",
    "\n",
    "### Central Tendency\n",
    "- **Mean**: Arithmetic average, sensitive to outliers\n",
    "- **Median**: Middle value, robust to outliers\n",
    "- **Mode**: Most frequent value, useful for categorical data\n",
    "\n",
    "### Dispersion\n",
    "- **Range**: Max - Min (simplest measure)\n",
    "- **Variance/Standard Deviation**: Measure spread around the mean\n",
    "- **IQR**: Range of middle 50%, robust to outliers\n",
    "- **Coefficient of Variation**: Relative variability (std/mean)\n",
    "\n",
    "### Probability\n",
    "- P(A) is between 0 and 1\n",
    "- P(not A) = 1 - P(A)\n",
    "- Independent events: P(A and B) = P(A) x P(B)\n",
    "- Conditional probability: P(A|B) = P(A and B) / P(B)\n",
    "\n",
    "### Probability Distributions\n",
    "- **Normal**: Bell curve, described by mean and std\n",
    "- **Binomial**: Number of successes in n trials\n",
    "- **Poisson**: Count of events in a time period\n",
    "\n",
    "### Hypothesis Testing\n",
    "- State null (H0) and alternative (H1) hypotheses\n",
    "- Calculate test statistic and p-value\n",
    "- Reject H0 if p-value < alpha (typically 0.05)\n",
    "- Be aware of Type I and Type II errors\n",
    "\n",
    "### Correlation\n",
    "- Pearson's r measures linear relationship (-1 to +1)\n",
    "- Spearman's rho measures monotonic relationship\n",
    "- Correlation does NOT imply causation!\n",
    "\n",
    "### A/B Testing\n",
    "- Randomly assign users to control and treatment groups\n",
    "- Calculate conversion rates and statistical significance\n",
    "- Consider sample size requirements for detecting effects\n",
    "\n",
    "## Next Module\n",
    "In the next module, we'll explore Introduction to Machine Learning, where you'll learn how to build predictive models using the statistical foundation we've established.\n",
    "\n",
    "## Additional Practice\n",
    "For extra practice, try these challenges:\n",
    "1. Analyze the distribution of a real dataset (e.g., Kaggle) and report all descriptive statistics\n",
    "2. Design an A/B test for a feature in an app you use frequently\n",
    "3. Find examples of spurious correlations and explain the confounding variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
