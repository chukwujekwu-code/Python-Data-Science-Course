{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 19: Classification Algorithms\n\n## Topics Covered\n1. K-Nearest Neighbors\n2. Decision Trees\n3. Random Forests\n4. Support Vector Machines\n5. Naive Bayes\n6. Algorithm Comparison\n7. When to Use Which\n8. Hyperparameter Tuning\n\n## Learning Objectives\n\nBy the end of this module, you will be able to:\n- Understand and apply k-nearest neighbors\n- Work with decision trees effectively\n- Implement random forests in practice\n- Evaluate models using appropriate metrics and techniques\n- Apply these concepts to real-world data science problems\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n# Section 1: K-Nearest Neighbors (KNN)\n---\n\n## What is K-Nearest Neighbors (KNN)?\n\nKNN classifies data points based on the majority class of their k nearest neighbors. It's simple, intuitive, and doesn't require training, but can be slow for large datasets.\n\n### Why This Matters in Data Science\n\nThis technique is essential for building effective machine learning models. It's used across industries for problems ranging from customer segmentation to fraud detection, recommendation systems, and predictive analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: K-Nearest Neighbors (KNN)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate synthetic data\nnp.random.seed(42)\nn_samples = 200\n\n# Create sample dataset\nX = np.random.randn(n_samples, 2)\ny = (X[:, 0] + X[:, 1] > 0).astype(int)\n\nprint(f\"Dataset shape: {X.shape}\")\nprint(f\"Class distribution: {np.bincount(y)}\")\n\n# Visualize data\nplt.figure(figsize=(10, 6))\nplt.scatter(X[y==0, 0], X[y==0, 1], label='Class 0', alpha=0.6, s=50)\nplt.scatter(X[y==1, 0], X[y==1, 1], label='Class 1', alpha=0.6, s=50)\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.title(f'{data[\"section1\"][\"title\"]} - Sample Data')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Building and Evaluating a Model\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"Training set size: {len(X_train)}\")\nprint(f\"Test set size: {len(X_test)}\")\nprint(f\"\\nFeatures are now scaled with mean=0 and std=1\")\nprint(f\"Training data mean: {X_train_scaled.mean(axis=0)}\")\nprint(f\"Training data std: {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 1.1\n\n**Task:** Apply K-Nearest Neighbors to a real-world scenario:\n\nCreate a synthetic dataset with 150 samples and 3 features. Split it into training and test sets (80/20). Scale the features and visualize the first two features colored by class.\n\n**Expected Output:**\n```\nTraining samples: 120\nTest samples: 30\nFeatures scaled successfully\n```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Your code here\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.1\n\n# Create dataset\nnp.random.seed(42)\nX_practice = np.random.randn(150, 3)\ny_practice = (X_practice.sum(axis=1) > 0).astype(int)\n\n# Split data\nX_tr, X_te, y_tr, y_te = train_test_split(X_practice, y_practice, test_size=0.2, random_state=42)\n\n# Scale\nscaler = StandardScaler()\nX_tr_scaled = scaler.fit_transform(X_tr)\nX_te_scaled = scaler.transform(X_te)\n\nprint(f\"Training samples: {len(X_tr)}\")\nprint(f\"Test samples: {len(X_te)}\")\nprint(\"Features scaled successfully\")\n\n# Visualize\nplt.figure(figsize=(10, 6))\nplt.scatter(X_tr_scaled[y_tr==0, 0], X_tr_scaled[y_tr==0, 1], label='Class 0', alpha=0.6)\nplt.scatter(X_tr_scaled[y_tr==1, 0], X_tr_scaled[y_tr==1, 1], label='Class 1', alpha=0.6)\nplt.xlabel('Feature 1 (scaled)')\nplt.ylabel('Feature 2 (scaled)')\nplt.title('Training Data Visualization')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n# Section 2: Decision Trees and Random Forests\n---\n\n## Understanding Decision Trees and Random Forests\n\nDecision trees split data recursively based on feature values. Random Forests combine multiple trees to reduce overfitting and improve performance.\n\n### Why This Matters in Data Science\n\nProper evaluation is critical for understanding model performance in production. Different metrics highlight different strengths and weaknesses, helping you choose the right model for your specific business needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Decision Trees and Random Forests in Practice\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n# Create sample predictions (you would use real model predictions)\nnp.random.seed(42)\ny_true = np.random.randint(0, 2, 100)\ny_pred = y_true.copy()\n# Add some errors\nerror_indices = np.random.choice(100, 15, replace=False)\ny_pred[error_indices] = 1 - y_pred[error_indices]\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\n\n# Visualize confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 2.1\n\n**Task:** Evaluate model performance:\n\nGiven true labels and predictions:\n```python\ny_true = [0, 1, 1, 0, 1, 1, 0, 0, 1, 0]\ny_pred = [0, 1, 1, 0, 0, 1, 0, 1, 1, 0]\n```\n\n1. Create a confusion matrix\n2. Calculate accuracy\n3. Calculate precision and recall\n4. Interpret the results\n\n**Expected Output:**\n```\nAccuracy: 0.80\nPrecision: 0.75\nRecall: 0.75\n```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Your code here\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2.1\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\ny_true = np.array([0, 1, 1, 0, 1, 1, 0, 0, 1, 0])\ny_pred = np.array([0, 1, 1, 0, 0, 1, 0, 1, 1, 0])\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\nprint(f\"True Negatives: {cm[0,0]}\")\nprint(f\"False Positives: {cm[0,1]}\")\nprint(f\"False Negatives: {cm[1,0]}\")\nprint(f\"True Positives: {cm[1,1]}\")\n\n# Calculate metrics\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred)\n\nprint(f\"\\nAccuracy: {accuracy:.2f}\")\nprint(f\"Precision: {precision:.2f}\")\nprint(f\"Recall: {recall:.2f}\")\n\nprint(\"\\nInterpretation:\")\nprint(f\"- The model correctly classifies {accuracy*100:.0f}% of all samples\")\nprint(f\"- Of all positive predictions, {precision*100:.0f}% were correct\")\nprint(f\"- Of all actual positives, {recall*100:.0f}% were identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n# Module Summary\n\n## Key Takeaways\n\n- **K-Nearest Neighbors** is essential for classification algorithms\n- **Decision Trees** is essential for classification algorithms\n- **Random Forests** is essential for classification algorithms\n- Understanding when and how to apply these techniques is crucial for success\n- Model evaluation must use appropriate metrics for the problem type\n- Real-world applications require careful consideration of trade-offs\n- Practice with diverse datasets strengthens your understanding\n\n## Next Module\n\nIn the next module, we'll continue building your machine learning toolkit with more advanced techniques and algorithms. You'll learn how to tackle increasingly complex problems with confidence.\n\n## Additional Practice\n\nFor extra practice, try these challenges:\n\n1. Apply K-Nearest Neighbors to the Iris dataset from sklearn\n2. Compare Decision Trees with Random Forests on a real dataset\n3. Experiment with different hyperparameters and observe the impact\n4. Create a complete pipeline from data loading to model evaluation\n5. Visualize decision boundaries for different models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}