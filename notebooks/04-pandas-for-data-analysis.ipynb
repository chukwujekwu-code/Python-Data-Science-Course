{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7: Pandas for Data Analysis\n",
    "\n",
    "## Topics Covered\n",
    "1. Introduction to Pandas - Series and DataFrames\n",
    "2. Reading Data (CSV, Excel, JSON)\n",
    "3. Exploring DataFrames (head, info, describe)\n",
    "4. Selecting Data - loc and iloc\n",
    "5. Filtering and Boolean Indexing\n",
    "6. Handling Missing Data\n",
    "7. Data Types and Type Conversion\n",
    "8. Adding and Removing Columns\n",
    "9. Sorting and Ranking\n",
    "10. Groupby Operations\n",
    "11. Merging and Joining DataFrames\n",
    "12. Pivot Tables and Cross-tabulation\n",
    "13. Apply, Map, and Applymap\n",
    "14. String Methods in Pandas\n",
    "15. DateTime Operations\n",
    "16. Exporting Data\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "- Create and manipulate pandas Series and DataFrames\n",
    "- Load data from various file formats\n",
    "- Select, filter, and transform data efficiently\n",
    "- Handle missing values appropriately\n",
    "- Aggregate and group data for analysis\n",
    "- Merge multiple datasets together\n",
    "- Work with text and datetime data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: Introduction to Pandas - Series and DataFrames\n",
    "---\n",
    "\n",
    "## What is Pandas?\n",
    "\n",
    "Pandas is the most important Python library for data analysis. It provides:\n",
    "\n",
    "- **DataFrame**: A 2D labeled data structure (like a spreadsheet)\n",
    "- **Series**: A 1D labeled array (like a column)\n",
    "- **Rich functionality**: Data manipulation, cleaning, analysis, and visualization\n",
    "\n",
    "### Why This Matters in Data Science\n",
    "\n",
    "Pandas is the foundation of the data science workflow in Python. It's used for:\n",
    "- Loading and saving data in various formats\n",
    "- Data cleaning and preprocessing\n",
    "- Exploratory data analysis\n",
    "- Feature engineering for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas (convention: import as 'pd')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "A Series is a one-dimensional labeled array. Think of it as a single column of data with an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a Series\n",
    "\n",
    "# From a list\n",
    "sales = pd.Series([100, 150, 200, 175, 225])\n",
    "print(\"Series from list:\")\n",
    "print(sales)\n",
    "print(f\"\\nIndex: {sales.index.tolist()}\")\n",
    "print(f\"Values: {sales.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Series with custom index\n",
    "\n",
    "sales = pd.Series(\n",
    "    [100, 150, 200, 175, 225],\n",
    "    index=['Mon', 'Tue', 'Wed', 'Thu', 'Fri']\n",
    ")\n",
    "print(\"Series with custom index:\")\n",
    "print(sales)\n",
    "\n",
    "# Access by label\n",
    "print(f\"\\nWednesday sales: {sales['Wed']}\")\n",
    "print(f\"Monday to Wednesday: \\n{sales['Mon':'Wed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Series from dictionary\n",
    "\n",
    "population = pd.Series({\n",
    "    'California': 39538223,\n",
    "    'Texas': 29145505,\n",
    "    'Florida': 21538187,\n",
    "    'New York': 20201249\n",
    "})\n",
    "print(\"Population by state:\")\n",
    "print(population)\n",
    "print(f\"\\nTexas population: {population['Texas']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "A DataFrame is a 2D labeled data structure with columns of potentially different types. Think of it as a spreadsheet or SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a DataFrame from a dictionary\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'age': [25, 30, 35, 28],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
    "    'salary': [70000, 80000, 90000, 75000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: DataFrame attributes\n",
    "\n",
    "print(f\"Shape: {df.shape}\")        # (rows, columns)\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Index: {df.index.tolist()}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Accessing columns (returns Series)\n",
    "\n",
    "# Using bracket notation\n",
    "print(\"Names column:\")\n",
    "print(df['name'])\n",
    "print(f\"\\nType: {type(df['name'])}\")\n",
    "\n",
    "# Using dot notation (only works for valid Python identifiers)\n",
    "print(f\"\\nAges: {df.age.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Selecting multiple columns\n",
    "\n",
    "subset = df[['name', 'salary']]\n",
    "print(\"Name and Salary:\")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 1.1\n",
    "\n",
    "**Task:** Create a DataFrame containing information about 5 products:\n",
    "- product_name: Laptop, Mouse, Keyboard, Monitor, Headphones\n",
    "- price: 999.99, 29.99, 79.99, 299.99, 149.99\n",
    "- quantity: 50, 200, 150, 75, 100\n",
    "\n",
    "Then calculate the total inventory value (price * quantity) for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "products = pd.DataFrame({\n",
    "    'product_name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'],\n",
    "    'price': [999.99, 29.99, 79.99, 299.99, 149.99],\n",
    "    'quantity': [50, 200, 150, 75, 100]\n",
    "})\n",
    "\n",
    "# Calculate inventory value\n",
    "products['inventory_value'] = products['price'] * products['quantity']\n",
    "\n",
    "print(\"Product Inventory:\")\n",
    "print(products)\n",
    "print(f\"\\nTotal Inventory Value: ${products['inventory_value'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Reading Data (CSV, Excel, JSON)\n",
    "---\n",
    "\n",
    "Pandas can read data from many file formats. The most common are CSV, Excel, and JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading a CSV file\n",
    "\n",
    "# Read the sales data\n",
    "sales_df = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "print(f\"Shape: {sales_df.shape}\")\n",
    "print(f\"Columns: {sales_df.columns.tolist()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(sales_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading with options\n",
    "\n",
    "# Common read_csv parameters:\n",
    "# - sep: delimiter (default ',')\n",
    "# - header: row number for column names\n",
    "# - names: list of column names\n",
    "# - usecols: which columns to read\n",
    "# - dtype: data types for columns\n",
    "# - parse_dates: columns to parse as dates\n",
    "# - na_values: values to treat as NA\n",
    "\n",
    "# Read only specific columns\n",
    "sales_subset = pd.read_csv(\n",
    "    'assets/datasets/sales_data.csv',\n",
    "    usecols=['transaction_id', 'date', 'product', 'total_amount']\n",
    ")\n",
    "print(\"Subset of columns:\")\n",
    "print(sales_subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading with date parsing\n",
    "\n",
    "sales_df = pd.read_csv(\n",
    "    'assets/datasets/sales_data.csv',\n",
    "    parse_dates=['date']\n",
    ")\n",
    "\n",
    "print(f\"Date column type: {sales_df['date'].dtype}\")\n",
    "print(f\"\\nDate range: {sales_df['date'].min()} to {sales_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading JSON\n",
    "\n",
    "# Read the products JSON file\n",
    "products_json = pd.read_json('assets/datasets/products.json')\n",
    "print(\"JSON data:\")\n",
    "print(products_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading nested JSON (common with API responses)\n",
    "\n",
    "import json\n",
    "\n",
    "# Load JSON file\n",
    "with open('assets/datasets/products.json', 'r') as f:\n",
    "    products_data = json.load(f)\n",
    "\n",
    "# Extract electronics products into DataFrame\n",
    "electronics = pd.DataFrame(products_data['categories']['Electronics']['products'])\n",
    "print(\"Electronics products:\")\n",
    "print(electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading employees CSV\n",
    "\n",
    "employees = pd.read_csv('assets/datasets/employees.csv')\n",
    "print(f\"Employees dataset: {employees.shape[0]} rows, {employees.shape[1]} columns\")\n",
    "print(\"\\nColumn names:\")\n",
    "print(employees.columns.tolist())\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(employees.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: Exploring DataFrames\n",
    "---\n",
    "\n",
    "Before analyzing data, you need to understand its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for exploration\n",
    "df = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: head() and tail()\n",
    "\n",
    "print(\"First 5 rows (head):\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nLast 3 rows (tail):\")\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: info() - overview of the DataFrame\n",
    "\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: describe() - statistical summary\n",
    "\n",
    "print(\"Statistical Summary (numeric columns):\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: describe() for all columns including non-numeric\n",
    "\n",
    "print(\"Summary of all columns:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Value counts for categorical columns\n",
    "\n",
    "print(\"Products sold (top 10):\")\n",
    "print(df['product'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nSales by region:\")\n",
    "print(df['region'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Unique values\n",
    "\n",
    "print(f\"Unique categories: {df['category'].unique()}\")\n",
    "print(f\"Number of unique products: {df['product'].nunique()}\")\n",
    "print(f\"Number of unique sales reps: {df['sales_rep'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Checking for missing values\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Percentage missing: {df.isnull().sum().sum() / df.size * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 3.1\n",
    "\n",
    "**Task:** Load the employees.csv file and answer:\n",
    "1. How many employees are there?\n",
    "2. What departments exist and how many employees in each?\n",
    "3. What is the average salary?\n",
    "4. Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3.1\n",
    "\n",
    "employees = pd.read_csv('assets/datasets/employees.csv')\n",
    "\n",
    "# 1. Number of employees\n",
    "print(f\"1. Total employees: {len(employees)}\")\n",
    "\n",
    "# 2. Departments and counts\n",
    "print(\"\\n2. Employees by department:\")\n",
    "print(employees['department'].value_counts())\n",
    "\n",
    "# 3. Average salary\n",
    "print(f\"\\n3. Average salary: ${employees['salary'].mean():,.2f}\")\n",
    "\n",
    "# 4. Missing values\n",
    "print(\"\\n4. Missing values:\")\n",
    "missing = employees.isnull().sum()\n",
    "print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Selecting Data - loc and iloc\n",
    "---\n",
    "\n",
    "Pandas provides two main ways to select data:\n",
    "- **loc**: Label-based selection\n",
    "- **iloc**: Integer position-based selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'age': [25, 30, 35, 28, 32],\n",
    "    'department': ['Sales', 'IT', 'HR', 'IT', 'Sales'],\n",
    "    'salary': [50000, 60000, 55000, 65000, 52000]\n",
    "}, index=['E001', 'E002', 'E003', 'E004', 'E005'])\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: loc - label-based selection\n",
    "\n",
    "# Single row by label\n",
    "print(\"Row E002:\")\n",
    "print(df.loc['E002'])\n",
    "\n",
    "# Multiple rows\n",
    "print(\"\\nRows E001 and E003:\")\n",
    "print(df.loc[['E001', 'E003']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: loc with row and column selection\n",
    "\n",
    "# Single value\n",
    "print(f\"E002's salary: {df.loc['E002', 'salary']}\")\n",
    "\n",
    "# Row with specific columns\n",
    "print(\"\\nE003's name and department:\")\n",
    "print(df.loc['E003', ['name', 'department']])\n",
    "\n",
    "# Multiple rows and columns\n",
    "print(\"\\nSubset:\")\n",
    "print(df.loc['E001':'E003', 'name':'department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: iloc - position-based selection\n",
    "\n",
    "# First row (position 0)\n",
    "print(\"First row (iloc[0]):\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "# Last row\n",
    "print(\"\\nLast row (iloc[-1]):\")\n",
    "print(df.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: iloc with slicing\n",
    "\n",
    "# First 3 rows\n",
    "print(\"First 3 rows:\")\n",
    "print(df.iloc[:3])\n",
    "\n",
    "# Rows 1-3, columns 0-2\n",
    "print(\"\\nRows 1-3, columns 0-2:\")\n",
    "print(df.iloc[1:4, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Modifying values with loc\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Update single value\n",
    "df_copy.loc['E002', 'salary'] = 65000\n",
    "print(\"After updating E002's salary:\")\n",
    "print(df_copy)\n",
    "\n",
    "# Update multiple values\n",
    "df_copy.loc['E001', ['department', 'salary']] = ['Marketing', 55000]\n",
    "print(\"\\nAfter updating E001:\")\n",
    "print(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: Filtering and Boolean Indexing\n",
    "---\n",
    "\n",
    "Filtering data based on conditions is one of the most common operations in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sales data\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "print(f\"Total records: {len(sales)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple filtering\n",
    "\n",
    "# Filter by category\n",
    "electronics = sales[sales['category'] == 'Electronics']\n",
    "print(f\"Electronics transactions: {len(electronics)}\")\n",
    "print(electronics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Numeric comparisons\n",
    "\n",
    "# High-value transactions\n",
    "high_value = sales[sales['total_amount'] > 500]\n",
    "print(f\"Transactions over $500: {len(high_value)}\")\n",
    "print(high_value.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multiple conditions\n",
    "\n",
    "# Use & for AND, | for OR (with parentheses!)\n",
    "filtered = sales[\n",
    "    (sales['category'] == 'Electronics') & \n",
    "    (sales['total_amount'] > 200)\n",
    "]\n",
    "print(f\"Electronics over $200: {len(filtered)}\")\n",
    "\n",
    "# OR condition\n",
    "filtered2 = sales[\n",
    "    (sales['region'] == 'North') | \n",
    "    (sales['region'] == 'South')\n",
    "]\n",
    "print(f\"North or South region: {len(filtered2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using isin() for multiple values\n",
    "\n",
    "# Filter for specific regions\n",
    "regions = ['North', 'Central']\n",
    "filtered = sales[sales['region'].isin(regions)]\n",
    "print(f\"North or Central: {len(filtered)}\")\n",
    "\n",
    "# Exclude certain products\n",
    "exclude_products = ['Laptop', 'Monitor 27inch']\n",
    "filtered2 = sales[~sales['product'].isin(exclude_products)]\n",
    "print(f\"Excluding Laptop and Monitor: {len(filtered2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: String methods for filtering\n",
    "\n",
    "# Products containing 'Mouse'\n",
    "mouse_products = sales[sales['product'].str.contains('Mouse', na=False)]\n",
    "print(f\"Mouse products: {len(mouse_products)}\")\n",
    "\n",
    "# Products starting with 'W'\n",
    "w_products = sales[sales['product'].str.startswith('W', na=False)]\n",
    "print(f\"Products starting with W: {len(w_products)}\")\n",
    "print(w_products['product'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using query() method (cleaner syntax)\n",
    "\n",
    "# Equivalent to boolean indexing\n",
    "result = sales.query('category == \"Electronics\" and total_amount > 200')\n",
    "print(f\"Electronics over $200 (using query): {len(result)}\")\n",
    "\n",
    "# With variables\n",
    "min_amount = 300\n",
    "result2 = sales.query('total_amount > @min_amount')\n",
    "print(f\"Transactions over ${min_amount}: {len(result2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 5.1\n",
    "\n",
    "**Task:** Using the sales data, find:\n",
    "1. All transactions from the Central region with quantity > 5\n",
    "2. All Furniture or Office Supplies transactions over $100\n",
    "3. Transactions where the sales_rep name contains 'son' (like Johnson, Wilson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 5.1\n",
    "\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# 1. Central region, quantity > 5\n",
    "central_high_qty = sales[(sales['region'] == 'Central') & (sales['quantity'] > 5)]\n",
    "print(f\"1. Central with qty > 5: {len(central_high_qty)} transactions\")\n",
    "\n",
    "# 2. Furniture or Office Supplies over $100\n",
    "furn_office = sales[\n",
    "    (sales['category'].isin(['Furniture', 'Office Supplies'])) & \n",
    "    (sales['total_amount'] > 100)\n",
    "]\n",
    "print(f\"2. Furniture/Office Supplies > $100: {len(furn_office)} transactions\")\n",
    "\n",
    "# 3. Sales rep containing 'son'\n",
    "son_reps = sales[sales['sales_rep'].str.contains('son', case=False, na=False)]\n",
    "print(f\"3. Sales reps with 'son': {len(son_reps)} transactions\")\n",
    "print(f\"   Reps: {son_reps['sales_rep'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Handling Missing Data\n",
    "---\n",
    "\n",
    "Real-world data often has missing values. Pandas uses `NaN` (Not a Number) to represent missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with missing values\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "print(\"Missing values:\")\n",
    "print(sales.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Finding rows with missing values\n",
    "\n",
    "# Rows with any missing value\n",
    "rows_with_missing = sales[sales.isnull().any(axis=1)]\n",
    "print(f\"Rows with missing values: {len(rows_with_missing)}\")\n",
    "print(rows_with_missing.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Dropping missing values\n",
    "\n",
    "# Drop rows with ANY missing value\n",
    "clean_df = sales.dropna()\n",
    "print(f\"Original: {len(sales)} rows\")\n",
    "print(f\"After dropna(): {len(clean_df)} rows\")\n",
    "\n",
    "# Drop rows only if specific columns are missing\n",
    "clean_df2 = sales.dropna(subset=['sales_rep', 'unit_price'])\n",
    "print(f\"After dropna(subset): {len(clean_df2)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Filling missing values\n",
    "\n",
    "df = sales.copy()\n",
    "\n",
    "# Fill with a specific value\n",
    "df['customer_rating'] = df['customer_rating'].fillna(0)\n",
    "\n",
    "# Fill with mean\n",
    "mean_price = df['unit_price'].mean()\n",
    "df['unit_price'] = df['unit_price'].fillna(mean_price)\n",
    "\n",
    "# Fill with a string\n",
    "df['sales_rep'] = df['sales_rep'].fillna('Unknown')\n",
    "\n",
    "print(\"After filling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Forward fill and backward fill\n",
    "\n",
    "# Useful for time series data\n",
    "data = pd.Series([1, np.nan, np.nan, 4, np.nan, 6])\n",
    "print(f\"Original: {data.tolist()}\")\n",
    "\n",
    "# Forward fill (use previous value)\n",
    "print(f\"Forward fill: {data.ffill().tolist()}\")\n",
    "\n",
    "# Backward fill (use next value)\n",
    "print(f\"Backward fill: {data.bfill().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 7: Data Types and Type Conversion\n",
    "---\n",
    "\n",
    "Correct data types are essential for proper analysis and memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Checking data types\n",
    "\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "print(\"Data types:\")\n",
    "print(sales.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Converting types with astype()\n",
    "\n",
    "df = sales.copy()\n",
    "\n",
    "# Convert to category (saves memory for repeated strings)\n",
    "df['category'] = df['category'].astype('category')\n",
    "df['region'] = df['region'].astype('category')\n",
    "\n",
    "print(\"After conversion:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nCategory values: {df['category'].cat.categories.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Converting dates\n",
    "\n",
    "df = sales.copy()\n",
    "print(f\"Date type before: {df['date'].dtype}\")\n",
    "\n",
    "# Convert to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "print(f\"Date type after: {df['date'].dtype}\")\n",
    "\n",
    "# Now we can use datetime operations\n",
    "print(f\"\\nYear range: {df['date'].dt.year.min()} - {df['date'].dt.year.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Numeric conversions with errors handling\n",
    "\n",
    "# Sample data with problematic values\n",
    "data = pd.Series(['10', '20', 'thirty', '40', None])\n",
    "print(f\"Original: {data.tolist()}\")\n",
    "\n",
    "# errors='coerce' converts invalid values to NaN\n",
    "numeric = pd.to_numeric(data, errors='coerce')\n",
    "print(f\"As numeric: {numeric.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 8: Adding and Removing Columns\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding new columns\n",
    "\n",
    "df = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Add calculated column\n",
    "df['unit_price_filled'] = df['unit_price'].fillna(df['total_amount'] / df['quantity'])\n",
    "\n",
    "# Add column with constant value\n",
    "df['currency'] = 'USD'\n",
    "\n",
    "# Add column based on condition\n",
    "df['high_value'] = df['total_amount'] > 200\n",
    "\n",
    "print(df[['transaction_id', 'total_amount', 'high_value', 'currency']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding column using np.where (if-else)\n",
    "\n",
    "df = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Create size category based on quantity\n",
    "df['order_size'] = np.where(df['quantity'] > 5, 'Large', 'Small')\n",
    "\n",
    "print(df[['product', 'quantity', 'order_size']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multiple conditions with np.select\n",
    "\n",
    "conditions = [\n",
    "    df['quantity'] <= 2,\n",
    "    df['quantity'] <= 5,\n",
    "    df['quantity'] <= 10,\n",
    "    df['quantity'] > 10\n",
    "]\n",
    "choices = ['XS', 'S', 'M', 'L']\n",
    "\n",
    "df['size_category'] = np.select(conditions, choices)\n",
    "\n",
    "print(\"Order size distribution:\")\n",
    "print(df['size_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Removing columns\n",
    "\n",
    "df = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "print(f\"Columns before: {df.columns.tolist()}\")\n",
    "\n",
    "# Drop single column\n",
    "df = df.drop('customer_rating', axis=1)\n",
    "\n",
    "# Drop multiple columns\n",
    "df = df.drop(['sales_rep', 'unit_price'], axis=1)\n",
    "\n",
    "print(f\"Columns after: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 9: Sorting and Ranking\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sorting by values\n",
    "\n",
    "df = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Sort by single column\n",
    "sorted_by_amount = df.sort_values('total_amount', ascending=False)\n",
    "print(\"Top 5 transactions by amount:\")\n",
    "print(sorted_by_amount[['transaction_id', 'product', 'total_amount']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sorting by multiple columns\n",
    "\n",
    "# Sort by category (asc), then by total_amount (desc)\n",
    "sorted_multi = df.sort_values(\n",
    "    ['category', 'total_amount'], \n",
    "    ascending=[True, False]\n",
    ")\n",
    "print(\"Sorted by category then amount:\")\n",
    "print(sorted_multi[['category', 'product', 'total_amount']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Ranking\n",
    "\n",
    "df = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Add rank column\n",
    "df['amount_rank'] = df['total_amount'].rank(ascending=False)\n",
    "\n",
    "# Show top ranked\n",
    "top_ranked = df.nsmallest(5, 'amount_rank')\n",
    "print(\"Top 5 by rank:\")\n",
    "print(top_ranked[['transaction_id', 'total_amount', 'amount_rank']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: nlargest and nsmallest\n",
    "\n",
    "# Top 5 highest amounts\n",
    "print(\"Top 5 highest:\")\n",
    "print(df.nlargest(5, 'total_amount')[['transaction_id', 'product', 'total_amount']])\n",
    "\n",
    "# Bottom 5\n",
    "print(\"\\nBottom 5:\")\n",
    "print(df.nsmallest(5, 'total_amount')[['transaction_id', 'product', 'total_amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 10: Groupby Operations\n",
    "---\n",
    "\n",
    "Groupby is one of the most powerful features in pandas. It allows you to:\n",
    "1. **Split** data into groups\n",
    "2. **Apply** a function to each group\n",
    "3. **Combine** results into a new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Example: Basic groupby with single aggregation\n",
    "sales_by_region = sales.groupby('region')['total_amount'].sum()\n",
    "print(\"Total sales by region:\")\n",
    "print(sales_by_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multiple aggregations\n",
    "\n",
    "region_stats = sales.groupby('region')['total_amount'].agg(['sum', 'mean', 'count'])\n",
    "print(\"Region statistics:\")\n",
    "print(region_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Named aggregations (recommended approach)\n",
    "\n",
    "region_summary = sales.groupby('region').agg(\n",
    "    total_sales=('total_amount', 'sum'),\n",
    "    avg_sale=('total_amount', 'mean'),\n",
    "    num_transactions=('transaction_id', 'count'),\n",
    "    avg_quantity=('quantity', 'mean')\n",
    ").round(2)\n",
    "\n",
    "print(\"Region summary:\")\n",
    "print(region_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Group by multiple columns\n",
    "\n",
    "category_region = sales.groupby(['category', 'region']).agg(\n",
    "    total_sales=('total_amount', 'sum'),\n",
    "    num_transactions=('transaction_id', 'count')\n",
    ").round(2)\n",
    "\n",
    "print(\"Sales by category and region:\")\n",
    "print(category_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Resetting index after groupby\n",
    "\n",
    "category_region_flat = sales.groupby(['category', 'region']).agg(\n",
    "    total_sales=('total_amount', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Flattened result:\")\n",
    "print(category_region_flat.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Transform - apply function and keep original shape\n",
    "\n",
    "# Calculate each transaction's percentage of region total\n",
    "sales['region_total'] = sales.groupby('region')['total_amount'].transform('sum')\n",
    "sales['pct_of_region'] = (sales['total_amount'] / sales['region_total'] * 100).round(2)\n",
    "\n",
    "print(\"Sample with percentages:\")\n",
    "print(sales[['region', 'total_amount', 'region_total', 'pct_of_region']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 10.1\n",
    "\n",
    "**Task:** Using the sales data:\n",
    "1. Find the total sales and average transaction amount for each product\n",
    "2. Find the top-selling product in each category (by total sales)\n",
    "3. Calculate what percentage each category contributes to total sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 10.1\n",
    "\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# 1. Total and average by product\n",
    "product_stats = sales.groupby('product').agg(\n",
    "    total_sales=('total_amount', 'sum'),\n",
    "    avg_transaction=('total_amount', 'mean')\n",
    ").round(2).sort_values('total_sales', ascending=False)\n",
    "\n",
    "print(\"1. Product statistics (top 10):\")\n",
    "print(product_stats.head(10))\n",
    "\n",
    "# 2. Top product per category\n",
    "category_product = sales.groupby(['category', 'product'])['total_amount'].sum().reset_index()\n",
    "top_per_category = category_product.loc[\n",
    "    category_product.groupby('category')['total_amount'].idxmax()\n",
    "]\n",
    "print(\"\\n2. Top product per category:\")\n",
    "print(top_per_category)\n",
    "\n",
    "# 3. Category percentage of total\n",
    "total_sales = sales['total_amount'].sum()\n",
    "category_pct = (sales.groupby('category')['total_amount'].sum() / total_sales * 100).round(2)\n",
    "print(\"\\n3. Category share of total sales:\")\n",
    "print(category_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 11: Merging and Joining DataFrames\n",
    "---\n",
    "\n",
    "Combining data from multiple sources is essential in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [1, 2, 3, 4, 5],\n",
    "    'customer_id': ['C001', 'C002', 'C001', 'C003', 'C002'],\n",
    "    'amount': [100, 200, 150, 300, 250]\n",
    "})\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': ['C001', 'C002', 'C003', 'C004'],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'city': ['NYC', 'LA', 'Chicago', 'Houston']\n",
    "})\n",
    "\n",
    "print(\"Orders:\")\n",
    "print(orders)\n",
    "print(\"\\nCustomers:\")\n",
    "print(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inner merge (only matching rows)\n",
    "\n",
    "merged = pd.merge(orders, customers, on='customer_id', how='inner')\n",
    "print(\"Inner merge:\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Left merge (keep all rows from left)\n",
    "\n",
    "merged_left = pd.merge(orders, customers, on='customer_id', how='left')\n",
    "print(\"Left merge:\")\n",
    "print(merged_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Right merge (keep all rows from right)\n",
    "\n",
    "merged_right = pd.merge(orders, customers, on='customer_id', how='right')\n",
    "print(\"Right merge:\")\n",
    "print(merged_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Outer merge (keep all rows from both)\n",
    "\n",
    "merged_outer = pd.merge(orders, customers, on='customer_id', how='outer')\n",
    "print(\"Outer merge:\")\n",
    "print(merged_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Merging on different column names\n",
    "\n",
    "df1 = pd.DataFrame({'emp_id': [1, 2, 3], 'name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'employee_id': [1, 2, 4], 'salary': [50000, 60000, 55000]})\n",
    "\n",
    "merged = pd.merge(df1, df2, left_on='emp_id', right_on='employee_id', how='inner')\n",
    "print(\"Merge on different column names:\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Concatenating DataFrames\n",
    "\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "# Vertical concatenation (stacking rows)\n",
    "stacked = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"Vertical concat:\")\n",
    "print(stacked)\n",
    "\n",
    "# Horizontal concatenation (adding columns)\n",
    "df3 = pd.DataFrame({'C': [9, 10]})\n",
    "combined = pd.concat([df1, df3], axis=1)\n",
    "print(\"\\nHorizontal concat:\")\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 12: Pivot Tables and Cross-tabulation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sales data\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Example: Basic pivot table\n",
    "pivot = pd.pivot_table(\n",
    "    sales,\n",
    "    values='total_amount',\n",
    "    index='category',\n",
    "    columns='region',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "print(\"Pivot table - Sales by Category and Region:\")\n",
    "print(pivot.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Pivot with multiple aggregations\n",
    "\n",
    "pivot_multi = pd.pivot_table(\n",
    "    sales,\n",
    "    values='total_amount',\n",
    "    index='category',\n",
    "    columns='region',\n",
    "    aggfunc=['sum', 'mean', 'count']\n",
    ")\n",
    "print(\"Pivot with multiple aggregations:\")\n",
    "print(pivot_multi.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Pivot with margins (totals)\n",
    "\n",
    "pivot_margins = pd.pivot_table(\n",
    "    sales,\n",
    "    values='total_amount',\n",
    "    index='category',\n",
    "    columns='region',\n",
    "    aggfunc='sum',\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "print(\"Pivot with margins:\")\n",
    "print(pivot_margins.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Cross-tabulation (counts)\n",
    "\n",
    "crosstab = pd.crosstab(sales['category'], sales['region'])\n",
    "print(\"Cross-tabulation (counts):\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Cross-tabulation with percentages\n",
    "\n",
    "crosstab_pct = pd.crosstab(\n",
    "    sales['category'], \n",
    "    sales['region'],\n",
    "    normalize='index'  # Row percentages\n",
    ") * 100\n",
    "\n",
    "print(\"Cross-tabulation (row percentages):\")\n",
    "print(crosstab_pct.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 13: Apply, Map, and Applymap\n",
    "---\n",
    "\n",
    "These methods allow you to apply custom functions to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: apply() on Series\n",
    "\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Apply a function to each value\n",
    "def categorize_amount(amount):\n",
    "    if amount < 100:\n",
    "        return 'Small'\n",
    "    elif amount < 500:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Large'\n",
    "\n",
    "sales['amount_category'] = sales['total_amount'].apply(categorize_amount)\n",
    "print(sales[['total_amount', 'amount_category']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: apply() with lambda\n",
    "\n",
    "# Square root of amount\n",
    "sales['amount_sqrt'] = sales['total_amount'].apply(lambda x: np.sqrt(x))\n",
    "\n",
    "# Discount calculation\n",
    "sales['discount_price'] = sales['total_amount'].apply(lambda x: x * 0.9)\n",
    "\n",
    "print(sales[['total_amount', 'amount_sqrt', 'discount_price']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: apply() on DataFrame (row-wise)\n",
    "\n",
    "def calc_adjusted_amount(row):\n",
    "    base = row['total_amount']\n",
    "    if row['category'] == 'Electronics':\n",
    "        return base * 1.1  # 10% markup\n",
    "    elif row['category'] == 'Furniture':\n",
    "        return base * 0.95  # 5% discount\n",
    "    else:\n",
    "        return base\n",
    "\n",
    "sales['adjusted_amount'] = sales.apply(calc_adjusted_amount, axis=1)\n",
    "print(sales[['category', 'total_amount', 'adjusted_amount']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: map() for value replacement\n",
    "\n",
    "region_mapping = {\n",
    "    'North': 'N',\n",
    "    'South': 'S',\n",
    "    'East': 'E',\n",
    "    'West': 'W',\n",
    "    'Central': 'C'\n",
    "}\n",
    "\n",
    "sales['region_code'] = sales['region'].map(region_mapping)\n",
    "print(sales[['region', 'region_code']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: map() on DataFrame (element-wise) - now called map() instead of applymap()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1.234, 2.567, 3.891],\n",
    "    'B': [4.123, 5.456, 6.789]\n",
    "})\n",
    "\n",
    "# Format all values to 1 decimal place\n",
    "formatted = df.map(lambda x: f'{x:.1f}')\n",
    "print(\"Formatted DataFrame:\")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 14: String Methods in Pandas\n",
    "---\n",
    "\n",
    "Pandas provides string methods through the `.str` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Basic string methods\n",
    "\n",
    "employees = pd.read_csv('assets/datasets/employees.csv')\n",
    "\n",
    "# Create full name\n",
    "employees['full_name'] = employees['first_name'] + ' ' + employees['last_name']\n",
    "\n",
    "# Upper and lower case\n",
    "print(\"Upper case names:\")\n",
    "print(employees['full_name'].str.upper().head())\n",
    "\n",
    "print(\"\\nLower case:\")\n",
    "print(employees['full_name'].str.lower().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: String contains, starts with, ends with\n",
    "\n",
    "# Find managers\n",
    "managers = employees[employees['title'].str.contains('Manager', na=False)]\n",
    "print(f\"Managers: {len(managers)}\")\n",
    "print(managers['title'].unique())\n",
    "\n",
    "# Names starting with 'J'\n",
    "j_names = employees[employees['first_name'].str.startswith('J')]\n",
    "print(f\"\\nNames starting with J: {len(j_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: String length and slicing\n",
    "\n",
    "# Get length of names\n",
    "employees['name_length'] = employees['first_name'].str.len()\n",
    "\n",
    "# Get first 3 characters\n",
    "employees['initials'] = employees['first_name'].str[:1] + employees['last_name'].str[:1]\n",
    "\n",
    "print(employees[['first_name', 'last_name', 'name_length', 'initials']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: String split and extract\n",
    "\n",
    "# Extract username from email\n",
    "employees['username'] = employees['email'].str.split('@').str[0]\n",
    "\n",
    "print(employees[['email', 'username']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: String replace\n",
    "\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# Replace in product names\n",
    "sales['product_clean'] = sales['product'].str.replace(' ', '_')\n",
    "print(sales[['product', 'product_clean']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 15: DateTime Operations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse dates\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv', parse_dates=['date'])\n",
    "print(f\"Date column type: {sales['date'].dtype}\")\n",
    "print(sales['date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extracting date components\n",
    "\n",
    "sales['year'] = sales['date'].dt.year\n",
    "sales['month'] = sales['date'].dt.month\n",
    "sales['day'] = sales['date'].dt.day\n",
    "sales['day_of_week'] = sales['date'].dt.day_name()\n",
    "sales['quarter'] = sales['date'].dt.quarter\n",
    "\n",
    "print(sales[['date', 'year', 'month', 'day', 'day_of_week', 'quarter']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Filtering by date\n",
    "\n",
    "# Sales in 2023\n",
    "sales_2023 = sales[sales['date'].dt.year == 2023]\n",
    "print(f\"Sales in 2023: {len(sales_2023)}\")\n",
    "\n",
    "# Sales in Q4\n",
    "sales_q4 = sales[sales['quarter'] == 4]\n",
    "print(f\"Q4 sales: {len(sales_q4)}\")\n",
    "\n",
    "# Date range filter\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-06-30'\n",
    "sales_h1 = sales[(sales['date'] >= start_date) & (sales['date'] <= end_date)]\n",
    "print(f\"H1 2023 sales: {len(sales_h1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Grouping by time periods\n",
    "\n",
    "# Monthly sales\n",
    "monthly_sales = sales.groupby(sales['date'].dt.to_period('M'))['total_amount'].sum()\n",
    "print(\"Monthly sales (first 6 months):\")\n",
    "print(monthly_sales.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Date arithmetic\n",
    "\n",
    "sales['days_ago'] = (pd.Timestamp.now() - sales['date']).dt.days\n",
    "\n",
    "print(\"Recent transactions:\")\n",
    "print(sales[['date', 'days_ago']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 16: Exporting Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame to export\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "summary = sales.groupby('category').agg(\n",
    "    total_sales=('total_amount', 'sum'),\n",
    "    avg_sale=('total_amount', 'mean'),\n",
    "    num_transactions=('transaction_id', 'count')\n",
    ").round(2)\n",
    "\n",
    "print(\"Summary to export:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Export to CSV\n",
    "\n",
    "summary.to_csv('assets/datasets/category_summary_export.csv')\n",
    "print(\"Exported to CSV\")\n",
    "\n",
    "# Without index\n",
    "summary.to_csv('assets/datasets/category_summary_no_index.csv', index=False)\n",
    "print(\"Exported to CSV (no index)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Export to JSON\n",
    "\n",
    "# Different orientations\n",
    "summary.reset_index().to_json('assets/datasets/summary_records.json', orient='records', indent=2)\n",
    "print(\"Exported to JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Verify exports\n",
    "\n",
    "print(\"Verify CSV export:\")\n",
    "verify_df = pd.read_csv('assets/datasets/category_summary_export.csv')\n",
    "print(verify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 16.1\n",
    "\n",
    "**Task:** Create a comprehensive sales report:\n",
    "1. Load the sales data\n",
    "2. Create a summary with: total sales, average transaction, top product, top region for each category\n",
    "3. Export to both CSV and JSON formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 16.1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load data\n",
    "sales = pd.read_csv('assets/datasets/sales_data.csv')\n",
    "\n",
    "# 2. Create comprehensive summary\n",
    "# Basic aggregations\n",
    "summary = sales.groupby('category').agg(\n",
    "    total_sales=('total_amount', 'sum'),\n",
    "    avg_transaction=('total_amount', 'mean'),\n",
    "    num_transactions=('transaction_id', 'count')\n",
    ").round(2)\n",
    "\n",
    "# Find top product per category\n",
    "top_products = sales.groupby(['category', 'product'])['total_amount'].sum().reset_index()\n",
    "top_products = top_products.loc[top_products.groupby('category')['total_amount'].idxmax()]\n",
    "top_products = top_products.set_index('category')['product']\n",
    "\n",
    "# Find top region per category\n",
    "top_regions = sales.groupby(['category', 'region'])['total_amount'].sum().reset_index()\n",
    "top_regions = top_regions.loc[top_regions.groupby('category')['total_amount'].idxmax()]\n",
    "top_regions = top_regions.set_index('category')['region']\n",
    "\n",
    "# Add to summary\n",
    "summary['top_product'] = top_products\n",
    "summary['top_region'] = top_regions\n",
    "\n",
    "print(\"Sales Report by Category:\")\n",
    "print(summary)\n",
    "\n",
    "# 3. Export\n",
    "summary.to_csv('assets/datasets/sales_report.csv')\n",
    "summary.reset_index().to_json('assets/datasets/sales_report.json', orient='records', indent=2)\n",
    "\n",
    "print(\"\\nExported to sales_report.csv and sales_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Module Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **DataFrames and Series** are the core data structures in pandas\n",
    "2. **Reading data** with `read_csv()`, `read_json()`, `read_excel()`\n",
    "3. **Exploring data** with `head()`, `info()`, `describe()`, `value_counts()`\n",
    "4. **Selecting data** with `loc` (label-based) and `iloc` (position-based)\n",
    "5. **Filtering** with boolean indexing and `query()`\n",
    "6. **Missing data** handled with `dropna()`, `fillna()`\n",
    "7. **Groupby** for aggregations: split-apply-combine\n",
    "8. **Merging** DataFrames with `merge()` and `concat()`\n",
    "9. **Pivot tables** for multi-dimensional summaries\n",
    "10. **String and datetime** methods for text and time data\n",
    "\n",
    "## Essential Functions\n",
    "\n",
    "```python\n",
    "# Reading/Writing\n",
    "pd.read_csv(), df.to_csv()\n",
    "\n",
    "# Exploration\n",
    "df.head(), df.info(), df.describe(), df.value_counts()\n",
    "\n",
    "# Selection\n",
    "df.loc[], df.iloc[], df[condition]\n",
    "\n",
    "# Transformation\n",
    "df.groupby(), df.merge(), df.pivot_table()\n",
    "df.apply(), df['col'].str, df['col'].dt\n",
    "```\n",
    "\n",
    "## Next Module\n",
    "\n",
    "In the next module, we'll cover **Data Visualization** using Matplotlib and Seaborn to create informative charts and graphs from your data.\n",
    "\n",
    "## Additional Practice\n",
    "\n",
    "For extra practice, try these challenges:\n",
    "\n",
    "1. **Sales Dashboard**: Create a comprehensive analysis of the sales data including trends over time, regional comparisons, and product performance\n",
    "\n",
    "2. **Employee Analysis**: Using the employees dataset, analyze salary distributions by department, identify experience levels based on hire dates, and create performance rankings\n",
    "\n",
    "3. **Data Pipeline**: Create a pipeline that reads multiple data files, cleans and transforms them, joins them together, and exports summary reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
