{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12: Introduction to Machine Learning\n",
    "\n",
    "## Topics Covered\n",
    "1. What is Machine Learning?\n",
    "2. Types of ML (Supervised, Unsupervised, Reinforcement)\n",
    "3. The ML Workflow\n",
    "4. Train-Test Split\n",
    "5. Linear Regression\n",
    "6. Logistic Regression\n",
    "7. Decision Trees\n",
    "8. Model Evaluation Metrics\n",
    "9. Cross-Validation\n",
    "10. Introduction to Scikit-Learn\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "- Explain what machine learning is and identify different types of ML problems\n",
    "- Understand the complete machine learning workflow\n",
    "- Split data into training and testing sets properly\n",
    "- Build and evaluate linear regression models\n",
    "- Build and evaluate logistic regression models for classification\n",
    "- Implement decision tree models\n",
    "- Calculate and interpret model evaluation metrics\n",
    "- Apply cross-validation techniques\n",
    "- Use scikit-learn for machine learning tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries we'll use throughout this module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,\n",
    "                             accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris, load_boston, make_classification\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: What is Machine Learning?\n",
    "---\n",
    "\n",
    "## Definition\n",
    "\n",
    "Machine Learning (ML) is a subset of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed for each specific task.\n",
    "\n",
    "### Traditional Programming vs Machine Learning\n",
    "\n",
    "**Traditional Programming:**\n",
    "```\n",
    "Data + Rules → Program → Output\n",
    "```\n",
    "\n",
    "**Machine Learning:**\n",
    "```\n",
    "Data + Output → ML Algorithm → Rules (Model)\n",
    "```\n",
    "\n",
    "### Why Machine Learning?\n",
    "\n",
    "Machine learning is useful when:\n",
    "- Rules are too complex to code manually (e.g., image recognition)\n",
    "- Rules change over time (e.g., spam detection)\n",
    "- Patterns are not obvious to humans (e.g., customer behavior)\n",
    "- Personalization is required (e.g., recommendations)\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "| Domain | Application |\n",
    "|--------|-------------|\n",
    "| Healthcare | Disease diagnosis, drug discovery |\n",
    "| Finance | Fraud detection, credit scoring |\n",
    "| Retail | Product recommendations, demand forecasting |\n",
    "| Transportation | Self-driving cars, route optimization |\n",
    "| Marketing | Customer segmentation, churn prediction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example: Traditional programming vs ML approach\n",
    "# Task: Predict house prices\n",
    "\n",
    "# Traditional approach - explicit rules (oversimplified)\n",
    "def predict_price_traditional(sqft, bedrooms, location_score):\n",
    "    \"\"\"Manual rules for house pricing - hard to get right!\"\"\"\n",
    "    base_price = 50000\n",
    "    price = base_price + (sqft * 100) + (bedrooms * 10000) + (location_score * 20000)\n",
    "    return price\n",
    "\n",
    "# ML approach - learn from data\n",
    "# Generate synthetic housing data\n",
    "np.random.seed(42)\n",
    "n_houses = 100\n",
    "\n",
    "sqft = np.random.uniform(1000, 3000, n_houses)\n",
    "bedrooms = np.random.randint(1, 6, n_houses)\n",
    "location_score = np.random.uniform(1, 10, n_houses)\n",
    "\n",
    "# True relationship (unknown to us in real scenarios)\n",
    "actual_prices = (50000 + sqft * 150 + bedrooms * 15000 + \n",
    "                 location_score * 25000 + np.random.normal(0, 20000, n_houses))\n",
    "\n",
    "# Create DataFrame\n",
    "housing_data = pd.DataFrame({\n",
    "    'sqft': sqft,\n",
    "    'bedrooms': bedrooms,\n",
    "    'location_score': location_score,\n",
    "    'price': actual_prices\n",
    "})\n",
    "\n",
    "print(\"Sample Housing Data:\")\n",
    "print(housing_data.head(10))\n",
    "print(f\"\\nDataset shape: {housing_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare traditional vs ML predictions\n",
    "# Traditional prediction\n",
    "housing_data['traditional_pred'] = housing_data.apply(\n",
    "    lambda row: predict_price_traditional(row['sqft'], row['bedrooms'], row['location_score']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ML prediction (Linear Regression - we'll learn this soon)\n",
    "X = housing_data[['sqft', 'bedrooms', 'location_score']]\n",
    "y = housing_data['price']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "housing_data['ml_pred'] = model.predict(X)\n",
    "\n",
    "# Compare errors\n",
    "traditional_error = np.sqrt(mean_squared_error(housing_data['price'], housing_data['traditional_pred']))\n",
    "ml_error = np.sqrt(mean_squared_error(housing_data['price'], housing_data['ml_pred']))\n",
    "\n",
    "print(\"Prediction Error Comparison (RMSE):\")\n",
    "print(f\"  Traditional rules: ${traditional_error:,.2f}\")\n",
    "print(f\"  Machine Learning:  ${ml_error:,.2f}\")\n",
    "print(f\"\\nML model reduces error by {((traditional_error - ml_error) / traditional_error * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Types of Machine Learning\n",
    "---\n",
    "\n",
    "## Three Main Categories\n",
    "\n",
    "### 1. Supervised Learning\n",
    "- Learning from labeled data (input-output pairs)\n",
    "- Goal: Learn a mapping from inputs to outputs\n",
    "- Examples: Spam detection, price prediction, image classification\n",
    "\n",
    "**Two types:**\n",
    "- **Regression**: Predict continuous values (e.g., house prices)\n",
    "- **Classification**: Predict categories (e.g., spam vs. not spam)\n",
    "\n",
    "### 2. Unsupervised Learning\n",
    "- Learning from unlabeled data\n",
    "- Goal: Find patterns or structure in data\n",
    "- Examples: Customer segmentation, anomaly detection\n",
    "\n",
    "**Common techniques:**\n",
    "- Clustering (K-means, hierarchical)\n",
    "- Dimensionality reduction (PCA)\n",
    "- Association rules\n",
    "\n",
    "### 3. Reinforcement Learning\n",
    "- Learning through interaction with an environment\n",
    "- Goal: Maximize cumulative reward\n",
    "- Examples: Game playing, robotics, autonomous vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of Supervised Learning types\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Regression example\n",
    "np.random.seed(42)\n",
    "x_reg = np.linspace(0, 10, 50)\n",
    "y_reg = 2 * x_reg + 3 + np.random.normal(0, 2, 50)\n",
    "\n",
    "axes[0].scatter(x_reg, y_reg, alpha=0.6)\n",
    "axes[0].plot(x_reg, 2 * x_reg + 3, color='red', linewidth=2, label='Predicted line')\n",
    "axes[0].set_xlabel('Feature (X)')\n",
    "axes[0].set_ylabel('Target (Y) - Continuous')\n",
    "axes[0].set_title('Regression: Predict Continuous Values')\n",
    "axes[0].legend()\n",
    "\n",
    "# Classification example\n",
    "from sklearn.datasets import make_blobs\n",
    "X_class, y_class = make_blobs(n_samples=100, centers=2, random_state=42, cluster_std=1.5)\n",
    "\n",
    "colors = ['blue' if label == 0 else 'orange' for label in y_class]\n",
    "axes[1].scatter(X_class[:, 0], X_class[:, 1], c=colors, alpha=0.6)\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].set_title('Classification: Predict Categories')\n",
    "\n",
    "# Add legend manually\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='blue', label='Class 0'),\n",
    "                   Patch(facecolor='orange', label='Class 1')]\n",
    "axes[1].legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised Learning example: Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate unlabeled data\n",
    "np.random.seed(42)\n",
    "X_unlabeled, _ = make_blobs(n_samples=150, centers=3, random_state=42, cluster_std=1.0)\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_unlabeled)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before clustering\n",
    "axes[0].scatter(X_unlabeled[:, 0], X_unlabeled[:, 1], alpha=0.6)\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].set_title('Before Clustering (No Labels)')\n",
    "\n",
    "# After clustering\n",
    "scatter = axes[1].scatter(X_unlabeled[:, 0], X_unlabeled[:, 1], \n",
    "                          c=cluster_labels, cmap='viridis', alpha=0.6)\n",
    "axes[1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                marker='X', s=200, c='red', edgecolor='black', linewidth=2,\n",
    "                label='Cluster Centers')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].set_title('After K-Means Clustering')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: The Machine Learning Workflow\n",
    "---\n",
    "\n",
    "## Standard ML Pipeline\n",
    "\n",
    "```\n",
    "1. Define Problem → 2. Collect Data → 3. Prepare Data → 4. Explore Data\n",
    "                                                              ↓\n",
    "8. Deploy Model ← 7. Fine-tune ← 6. Evaluate Model ← 5. Build Model\n",
    "```\n",
    "\n",
    "### Step-by-Step Breakdown\n",
    "\n",
    "1. **Define the Problem**\n",
    "   - What are you trying to predict?\n",
    "   - Is it regression or classification?\n",
    "   - What metrics define success?\n",
    "\n",
    "2. **Collect Data**\n",
    "   - Gather relevant data\n",
    "   - Ensure data quality\n",
    "   - Consider data privacy\n",
    "\n",
    "3. **Prepare Data**\n",
    "   - Handle missing values\n",
    "   - Encode categorical variables\n",
    "   - Scale/normalize features\n",
    "\n",
    "4. **Explore Data (EDA)**\n",
    "   - Understand distributions\n",
    "   - Identify patterns and correlations\n",
    "   - Detect outliers\n",
    "\n",
    "5. **Build Model**\n",
    "   - Select algorithm(s)\n",
    "   - Split data (train/test)\n",
    "   - Train the model\n",
    "\n",
    "6. **Evaluate Model**\n",
    "   - Test on unseen data\n",
    "   - Calculate performance metrics\n",
    "   - Compare with baseline\n",
    "\n",
    "7. **Fine-tune**\n",
    "   - Adjust hyperparameters\n",
    "   - Try different algorithms\n",
    "   - Feature engineering\n",
    "\n",
    "8. **Deploy**\n",
    "   - Put model into production\n",
    "   - Monitor performance\n",
    "   - Update as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's walk through a complete ML workflow example\n",
    "# Problem: Predict if a customer will make a purchase based on their behavior\n",
    "\n",
    "# Step 1: Define Problem\n",
    "print(\"STEP 1: Define Problem\")\n",
    "print(\"=\"*50)\n",
    "print(\"Task: Predict customer purchase (Yes/No)\")\n",
    "print(\"Type: Binary Classification\")\n",
    "print(\"Success Metric: Accuracy, with focus on Recall\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 & 3: Collect and Prepare Data\n",
    "print(\"STEP 2 & 3: Collect and Prepare Data\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generate synthetic customer data\n",
    "np.random.seed(42)\n",
    "n_customers = 500\n",
    "\n",
    "customer_data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 70, n_customers),\n",
    "    'income': np.random.normal(50000, 20000, n_customers).clip(20000, 150000),\n",
    "    'time_on_site': np.random.exponential(5, n_customers),  # minutes\n",
    "    'pages_viewed': np.random.poisson(5, n_customers),\n",
    "    'previous_purchases': np.random.poisson(2, n_customers),\n",
    "    'email_subscribed': np.random.choice([0, 1], n_customers, p=[0.4, 0.6])\n",
    "})\n",
    "\n",
    "# Create target variable (purchase) based on features\n",
    "purchase_probability = (\n",
    "    0.1 + \n",
    "    0.01 * (customer_data['income'] / 10000) +\n",
    "    0.05 * customer_data['time_on_site'] +\n",
    "    0.03 * customer_data['pages_viewed'] +\n",
    "    0.1 * customer_data['previous_purchases'] +\n",
    "    0.15 * customer_data['email_subscribed']\n",
    ").clip(0, 1)\n",
    "\n",
    "customer_data['purchased'] = np.random.binomial(1, purchase_probability)\n",
    "\n",
    "print(f\"Dataset shape: {customer_data.shape}\")\n",
    "print(f\"\\nFeatures: {list(customer_data.columns[:-1])}\")\n",
    "print(f\"Target: purchased\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(customer_data['purchased'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(customer_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Explore Data (Quick EDA)\n",
    "print(\"STEP 4: Explore Data\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(customer_data.describe().round(2))\n",
    "\n",
    "# Correlation with target\n",
    "print(\"\\nCorrelation with 'purchased':\")\n",
    "correlations = customer_data.corr()['purchased'].drop('purchased').sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions by purchase status\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "features = ['age', 'income', 'time_on_site', 'pages_viewed', 'previous_purchases', 'email_subscribed']\n",
    "\n",
    "for ax, feature in zip(axes.flat, features):\n",
    "    if feature == 'email_subscribed':\n",
    "        # Bar plot for binary feature\n",
    "        customer_data.groupby(['email_subscribed', 'purchased']).size().unstack().plot(\n",
    "            kind='bar', ax=ax, alpha=0.7)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.legend(['No Purchase', 'Purchase'])\n",
    "    else:\n",
    "        # Histogram for continuous features\n",
    "        customer_data[customer_data['purchased']==0][feature].hist(\n",
    "            ax=ax, alpha=0.5, label='No Purchase', bins=20)\n",
    "        customer_data[customer_data['purchased']==1][feature].hist(\n",
    "            ax=ax, alpha=0.5, label='Purchase', bins=20)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.legend()\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Train-Test Split\n",
    "---\n",
    "\n",
    "## Why Split the Data?\n",
    "\n",
    "We need to evaluate our model on data it hasn't seen during training. This helps us:\n",
    "\n",
    "1. **Estimate real-world performance**: How well will the model work on new data?\n",
    "2. **Detect overfitting**: Is the model memorizing training data instead of learning patterns?\n",
    "3. **Compare models fairly**: Consistent evaluation across different models\n",
    "\n",
    "### Common Split Ratios\n",
    "\n",
    "| Split | Training | Testing | Use Case |\n",
    "|-------|----------|---------|----------|\n",
    "| 80/20 | 80% | 20% | Most common, general purpose |\n",
    "| 70/30 | 70% | 30% | When you need more test data |\n",
    "| 90/10 | 90% | 10% | Large datasets |\n",
    "\n",
    "### Important Considerations\n",
    "\n",
    "- **Random sampling**: Ensure representative splits\n",
    "- **Stratification**: Maintain class proportions in imbalanced datasets\n",
    "- **No data leakage**: Test data should never influence training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Basic split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,              # Features\n",
    "    y,              # Target\n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42 # For reproducibility\n",
    ")\n",
    "\n",
    "# Stratified split (for classification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,     # Maintain class proportions\n",
    "    random_state=42\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 (Part 1): Split the data\n",
    "print(\"STEP 5 (Part 1): Train-Test Split\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Separate features and target\n",
    "X = customer_data.drop('purchased', axis=1)\n",
    "y = customer_data['purchased']\n",
    "\n",
    "# Split with stratification (important for imbalanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Testing samples: {len(X_test)} ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "\n",
    "print(f\"\\nClass distribution in original data:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the split\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Dataset sizes\n",
    "sizes = [len(X_train), len(X_test)]\n",
    "labels = [f'Training\\n({len(X_train)} samples)', f'Testing\\n({len(X_test)} samples)']\n",
    "colors = ['steelblue', 'coral']\n",
    "axes[0].pie(sizes, labels=labels, colors=colors, autopct='%1.0f%%', startangle=90)\n",
    "axes[0].set_title('Train-Test Split')\n",
    "\n",
    "# Class distribution\n",
    "x_pos = np.arange(2)\n",
    "width = 0.35\n",
    "\n",
    "train_dist = y_train.value_counts().sort_index().values\n",
    "test_dist = y_test.value_counts().sort_index().values\n",
    "\n",
    "bars1 = axes[1].bar(x_pos - width/2, train_dist, width, label='Training', color='steelblue')\n",
    "bars2 = axes[1].bar(x_pos + width/2, test_dist, width, label='Testing', color='coral')\n",
    "\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Class Distribution After Split')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(['No Purchase (0)', 'Purchase (1)'])\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: Linear Regression\n",
    "---\n",
    "\n",
    "## What is Linear Regression?\n",
    "\n",
    "Linear regression is a supervised learning algorithm that models the relationship between features and a continuous target variable by fitting a linear equation.\n",
    "\n",
    "### The Model\n",
    "\n",
    "**Simple Linear Regression** (one feature):\n",
    "```\n",
    "y = mx + b\n",
    "```\n",
    "- y: Predicted value\n",
    "- m: Slope (coefficient)\n",
    "- x: Feature value\n",
    "- b: Intercept\n",
    "\n",
    "**Multiple Linear Regression** (multiple features):\n",
    "```\n",
    "y = b0 + b1*x1 + b2*x2 + ... + bn*xn\n",
    "```\n",
    "\n",
    "### How It Works\n",
    "\n",
    "The algorithm finds the line (or hyperplane) that minimizes the sum of squared errors between predicted and actual values. This is called **Ordinary Least Squares (OLS)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Access model parameters\n",
    "coefficients = model.coef_       # Feature coefficients\n",
    "intercept = model.intercept_     # Intercept term\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict house prices with Linear Regression\n",
    "print(\"Linear Regression: House Price Prediction\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use our housing data from earlier\n",
    "X_house = housing_data[['sqft', 'bedrooms', 'location_score']]\n",
    "y_house = housing_data['price']\n",
    "\n",
    "# Split data\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
    "    X_house, y_house, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_h, y_train_h)\n",
    "\n",
    "# Model parameters\n",
    "print(\"Model Parameters:\")\n",
    "print(f\"  Intercept: ${lr_model.intercept_:,.2f}\")\n",
    "print(f\"\\n  Coefficients:\")\n",
    "for feature, coef in zip(X_house.columns, lr_model.coef_):\n",
    "    print(f\"    {feature}: ${coef:,.2f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - Base price (intercept): ${lr_model.intercept_:,.2f}\")\n",
    "print(f\"  - Each additional sqft adds ${lr_model.coef_[0]:,.2f}\")\n",
    "print(f\"  - Each additional bedroom adds ${lr_model.coef_[1]:,.2f}\")\n",
    "print(f\"  - Each point increase in location score adds ${lr_model.coef_[2]:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and evaluate\n",
    "y_pred_h = lr_model.predict(X_test_h)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test_h, y_pred_h)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_h, y_pred_h)\n",
    "r2 = r2_score(y_test_h, y_pred_h)\n",
    "\n",
    "print(\"Model Performance on Test Set:\")\n",
    "print(f\"  Mean Squared Error (MSE): ${mse:,.2f}\")\n",
    "print(f\"  Root Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
    "print(f\"  Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"  R-squared (R2): {r2:.4f}\")\n",
    "print(f\"\\nThe model explains {r2*100:.1f}% of the variance in house prices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_test_h, y_pred_h, alpha=0.5)\n",
    "axes[0].plot([y_test_h.min(), y_test_h.max()], [y_test_h.min(), y_test_h.max()], \n",
    "             'r--', linewidth=2, label='Perfect predictions')\n",
    "axes[0].set_xlabel('Actual Price ($)')\n",
    "axes[0].set_ylabel('Predicted Price ($)')\n",
    "axes[0].set_title('Actual vs Predicted House Prices')\n",
    "axes[0].legend()\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test_h - y_pred_h\n",
    "axes[1].scatter(y_pred_h, residuals, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted Price ($)')\n",
    "axes[1].set_ylabel('Residual ($)')\n",
    "axes[1].set_title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Logistic Regression\n",
    "---\n",
    "\n",
    "## What is Logistic Regression?\n",
    "\n",
    "Despite its name, logistic regression is a **classification** algorithm. It predicts the probability that an observation belongs to a particular class.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. Calculates a linear combination of features (like linear regression)\n",
    "2. Applies the **sigmoid function** to convert to probability (0 to 1)\n",
    "3. Uses a threshold (usually 0.5) to make final classification\n",
    "\n",
    "### The Sigmoid Function\n",
    "\n",
    "```\n",
    "P(y=1) = 1 / (1 + e^(-z))\n",
    "```\n",
    "\n",
    "Where z = b0 + b1*x1 + b2*x2 + ... + bn*xn\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- Email spam detection\n",
    "- Customer churn prediction\n",
    "- Disease diagnosis\n",
    "- Credit approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict class labels\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "y_prob = model.predict_proba(X_test)  # Returns [P(class=0), P(class=1)]\n",
    "\n",
    "# Access model parameters\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-10, 10, 100)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(z, sigmoid(z), linewidth=2)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Decision threshold (0.5)')\n",
    "plt.axvline(x=0, color='gray', linestyle=':', alpha=0.5)\n",
    "plt.xlabel('z (linear combination)')\n",
    "plt.ylabel('P(y=1)')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 (Part 2): Build Logistic Regression model for customer purchase prediction\n",
    "print(\"Logistic Regression: Customer Purchase Prediction\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Scale features for better convergence\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train model\n",
    "log_model = LogisticRegression(random_state=42)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Model coefficients\n",
    "print(\"Feature Importance (Coefficients):\")\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': log_model.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "print(coef_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nPositive coefficients increase purchase probability.\")\n",
    "print(f\"Negative coefficients decrease purchase probability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_class = log_model.predict(X_test_scaled)\n",
    "y_pred_prob = log_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Show sample predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test.values[:10],\n",
    "    'Predicted': y_pred_class[:10],\n",
    "    'P(No Purchase)': y_pred_prob[:10, 0].round(3),\n",
    "    'P(Purchase)': y_pred_prob[:10, 1].round(3)\n",
    "})\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(predictions_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate model performance\n",
    "print(\"STEP 6: Model Evaluation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "precision = precision_score(y_test, y_pred_class)\n",
    "recall = recall_score(y_test, y_pred_class)\n",
    "f1 = f1_score(y_test, y_pred_class)\n",
    "\n",
    "print(f\"\\nClassification Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_class, target_names=['No Purchase', 'Purchase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix visualization\n",
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['No Purchase', 'Purchase'],\n",
    "            yticklabels=['No Purchase', 'Purchase'])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "\n",
    "# Add annotations explaining the matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "axes[0].text(2.5, 0.5, f'TN={tn}\\nFP={fp}\\nFN={fn}\\nTP={tp}', \n",
    "             fontsize=10, verticalalignment='center')\n",
    "\n",
    "# Probability distribution\n",
    "axes[1].hist(y_pred_prob[y_test==0, 1], bins=20, alpha=0.5, label='Actual: No Purchase')\n",
    "axes[1].hist(y_pred_prob[y_test==1, 1], bins=20, alpha=0.5, label='Actual: Purchase')\n",
    "axes[1].axvline(x=0.5, color='r', linestyle='--', label='Decision Threshold')\n",
    "axes[1].set_xlabel('Predicted Probability of Purchase')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Predicted Probability Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 7: Decision Trees\n",
    "---\n",
    "\n",
    "## What are Decision Trees?\n",
    "\n",
    "Decision trees are versatile algorithms that can perform both classification and regression. They learn by splitting data based on feature values, creating a tree-like structure of decisions.\n",
    "\n",
    "### How They Work\n",
    "\n",
    "1. Start with all data at the root node\n",
    "2. Find the best feature and value to split the data\n",
    "3. Create child nodes for each split\n",
    "4. Repeat until stopping criteria are met\n",
    "5. Assign predictions at leaf nodes\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Easy to understand and interpret\n",
    "- Handle both numerical and categorical data\n",
    "- Require little data preprocessing\n",
    "- Can capture non-linear relationships\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- Prone to overfitting\n",
    "- Can be unstable (small changes in data = different tree)\n",
    "- May create biased trees with imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# For Classification\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=5,           # Limit tree depth to prevent overfitting\n",
    "    min_samples_split=10,  # Minimum samples to split a node\n",
    "    min_samples_leaf=5,    # Minimum samples in a leaf\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# For Regression\n",
    "reg = DecisionTreeRegressor(\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Feature importance\n",
    "importances = clf.feature_importances_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree for customer purchase prediction\n",
    "print(\"Decision Tree: Customer Purchase Prediction\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create and train model (use unscaled data - trees don't need scaling)\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=4,          # Limit depth to prevent overfitting and aid visualization\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"\\nDecision Tree Accuracy: {accuracy_dt:.4f} ({accuracy_dt*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=['No Purchase', 'Purchase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Decision Tree Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_model, \n",
    "          feature_names=X_train.columns,\n",
    "          class_names=['No Purchase', 'Purchase'],\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models: Logistic Regression vs Decision Tree\n",
    "print(\"Model Comparison\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Logistic Regression': [\n",
    "        accuracy_score(y_test, y_pred_class),\n",
    "        precision_score(y_test, y_pred_class),\n",
    "        recall_score(y_test, y_pred_class),\n",
    "        f1_score(y_test, y_pred_class)\n",
    "    ],\n",
    "    'Decision Tree': [\n",
    "        accuracy_score(y_test, y_pred_dt),\n",
    "        precision_score(y_test, y_pred_dt),\n",
    "        recall_score(y_test, y_pred_dt),\n",
    "        f1_score(y_test, y_pred_dt)\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df['Logistic Regression'] = comparison_df['Logistic Regression'].round(4)\n",
    "comparison_df['Decision Tree'] = comparison_df['Decision Tree'].round(4)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 8: Model Evaluation Metrics\n",
    "---\n",
    "\n",
    "## Regression Metrics\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| MSE | Mean of (actual - predicted)^2 | Lower is better, penalizes large errors |\n",
    "| RMSE | Square root of MSE | Same units as target, easier to interpret |\n",
    "| MAE | Mean of |actual - predicted| | Robust to outliers |\n",
    "| R-squared | 1 - (SS_res / SS_tot) | Proportion of variance explained (0-1) |\n",
    "\n",
    "## Classification Metrics\n",
    "\n",
    "| Metric | Formula | When to Use |\n",
    "|--------|---------|-------------|\n",
    "| Accuracy | (TP+TN) / Total | Balanced classes |\n",
    "| Precision | TP / (TP+FP) | When FP is costly |\n",
    "| Recall | TP / (TP+FN) | When FN is costly |\n",
    "| F1-Score | 2 * (Prec * Rec) / (Prec + Rec) | Balance between precision and recall |\n",
    "\n",
    "### Understanding the Confusion Matrix\n",
    "\n",
    "```\n",
    "                  Predicted\n",
    "                  Neg    Pos\n",
    "Actual  Neg      TN     FP\n",
    "        Pos      FN     TP\n",
    "```\n",
    "\n",
    "- **True Positive (TP)**: Correctly predicted positive\n",
    "- **True Negative (TN)**: Correctly predicted negative\n",
    "- **False Positive (FP)**: Incorrectly predicted positive (Type I error)\n",
    "- **False Negative (FN)**: Incorrectly predicted negative (Type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive into classification metrics\n",
    "print(\"Understanding Classification Metrics\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_class).ravel()\n",
    "\n",
    "print(f\"\\nConfusion Matrix Values:\")\n",
    "print(f\"  True Negatives (TN):  {tn} - Correctly predicted NO purchase\")\n",
    "print(f\"  False Positives (FP): {fp} - Incorrectly predicted purchase\")\n",
    "print(f\"  False Negatives (FN): {fn} - Incorrectly predicted NO purchase\")\n",
    "print(f\"  True Positives (TP):  {tp} - Correctly predicted purchase\")\n",
    "\n",
    "# Calculate metrics manually\n",
    "print(f\"\\nMetrics Calculated Manually:\")\n",
    "print(f\"  Accuracy = (TP+TN)/(TP+TN+FP+FN) = ({tp}+{tn})/({tp}+{tn}+{fp}+{fn}) = {(tp+tn)/(tp+tn+fp+fn):.4f}\")\n",
    "print(f\"  Precision = TP/(TP+FP) = {tp}/({tp}+{fp}) = {tp/(tp+fp):.4f}\")\n",
    "print(f\"  Recall = TP/(TP+FN) = {tp}/({tp}+{fn}) = {tp/(tp+fn):.4f}\")\n",
    "prec = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "print(f\"  F1 = 2*(Prec*Rec)/(Prec+Rec) = 2*({prec:.4f}*{rec:.4f})/({prec:.4f}+{rec:.4f}) = {2*prec*rec/(prec+rec):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When to use which metric - practical examples\n",
    "print(\"\\nChoosing the Right Metric:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "examples = [\n",
    "    (\"Spam Detection\", \"Precision\", \n",
    "     \"FP is costly: Important emails marked as spam\"),\n",
    "    (\"Disease Screening\", \"Recall\", \n",
    "     \"FN is costly: Missing a disease can be fatal\"),\n",
    "    (\"Fraud Detection\", \"Recall (with reasonable precision)\", \n",
    "     \"FN is costly: Missing fraud is expensive\"),\n",
    "    (\"Product Recommendations\", \"Precision\", \n",
    "     \"FP is annoying: Bad recommendations hurt UX\"),\n",
    "    (\"Credit Approval\", \"Balance (F1)\", \n",
    "     \"Both FP (bad loans) and FN (missed customers) are costly\")\n",
    "]\n",
    "\n",
    "for use_case, metric, reason in examples:\n",
    "    print(f\"\\n{use_case}:\")\n",
    "    print(f\"  Prioritize: {metric}\")\n",
    "    print(f\"  Why: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and AUC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Get probabilities\n",
    "y_prob_positive = log_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_positive)\n",
    "auc = roc_auc_score(y_test, y_prob_positive)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'Logistic Regression (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier (AUC = 0.5)')\n",
    "plt.fill_between(fpr, tpr, alpha=0.3)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC (Area Under Curve): {auc:.4f}\")\n",
    "print(f\"\\nInterpretation: The model has a {auc*100:.1f}% chance of ranking\")\n",
    "print(f\"a randomly chosen positive instance higher than a negative one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 8.1\n",
    "\n",
    "**Task:** Build and evaluate a classification model to predict customer churn.\n",
    "\n",
    "Use the following synthetic data:\n",
    "- Features: tenure (months), monthly_charges, total_charges, contract_type (0=month-to-month, 1=annual)\n",
    "- Target: churned (0=No, 1=Yes)\n",
    "\n",
    "Steps:\n",
    "1. Split the data (80/20)\n",
    "2. Train a Logistic Regression model\n",
    "3. Train a Decision Tree model\n",
    "4. Compare their performance using accuracy, precision, recall, and F1-score\n",
    "5. Which model would you recommend and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate churn dataset\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "churn_data = pd.DataFrame({\n",
    "    'tenure': np.random.randint(1, 72, n_customers),\n",
    "    'monthly_charges': np.random.uniform(20, 100, n_customers),\n",
    "    'contract_type': np.random.choice([0, 1], n_customers, p=[0.6, 0.4])\n",
    "})\n",
    "churn_data['total_charges'] = churn_data['tenure'] * churn_data['monthly_charges']\n",
    "\n",
    "# Create churn probability based on features\n",
    "churn_prob = (\n",
    "    0.5 - \n",
    "    0.01 * churn_data['tenure'] + \n",
    "    0.005 * churn_data['monthly_charges'] - \n",
    "    0.2 * churn_data['contract_type']\n",
    ").clip(0.05, 0.95)\n",
    "\n",
    "churn_data['churned'] = np.random.binomial(1, churn_prob)\n",
    "\n",
    "print(\"Churn Dataset:\")\n",
    "print(churn_data.head())\n",
    "print(f\"\\nChurn rate: {churn_data['churned'].mean():.2%}\")\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 8.1\n",
    "\n",
    "# Prepare data\n",
    "X_churn = churn_data.drop('churned', axis=1)\n",
    "y_churn = churn_data['churned']\n",
    "\n",
    "# Step 1: Split data\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_churn, y_churn, test_size=0.2, stratify=y_churn, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Step 1: Data Split\")\n",
    "print(f\"  Training: {len(X_train_c)}, Testing: {len(X_test_c)}\")\n",
    "\n",
    "# Scale for logistic regression\n",
    "scaler_c = StandardScaler()\n",
    "X_train_c_scaled = scaler_c.fit_transform(X_train_c)\n",
    "X_test_c_scaled = scaler_c.transform(X_test_c)\n",
    "\n",
    "# Step 2: Logistic Regression\n",
    "lr_churn = LogisticRegression(random_state=42)\n",
    "lr_churn.fit(X_train_c_scaled, y_train_c)\n",
    "y_pred_lr = lr_churn.predict(X_test_c_scaled)\n",
    "\n",
    "# Step 3: Decision Tree\n",
    "dt_churn = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dt_churn.fit(X_train_c, y_train_c)\n",
    "y_pred_dt = dt_churn.predict(X_test_c)\n",
    "\n",
    "# Step 4: Compare performance\n",
    "print(\"\\nStep 4: Model Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "lr_scores = [\n",
    "    accuracy_score(y_test_c, y_pred_lr),\n",
    "    precision_score(y_test_c, y_pred_lr),\n",
    "    recall_score(y_test_c, y_pred_lr),\n",
    "    f1_score(y_test_c, y_pred_lr)\n",
    "]\n",
    "dt_scores = [\n",
    "    accuracy_score(y_test_c, y_pred_dt),\n",
    "    precision_score(y_test_c, y_pred_dt),\n",
    "    recall_score(y_test_c, y_pred_dt),\n",
    "    f1_score(y_test_c, y_pred_dt)\n",
    "]\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'Logistic Regression': [f'{s:.4f}' for s in lr_scores],\n",
    "    'Decision Tree': [f'{s:.4f}' for s in dt_scores]\n",
    "})\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Step 5: Recommendation\n",
    "print(\"\\nStep 5: Recommendation\")\n",
    "print(\"=\"*60)\n",
    "print(\"For churn prediction, RECALL is often most important because:\")\n",
    "print(\"- Missing a churning customer (FN) means lost revenue\")\n",
    "print(\"- Reaching out to non-churners (FP) has lower cost\")\n",
    "print(f\"\\nBased on recall: {'Logistic Regression' if lr_scores[2] > dt_scores[2] else 'Decision Tree'} performs better.\")\n",
    "print(f\"However, also consider F1-score for balance: {'Logistic Regression' if lr_scores[3] > dt_scores[3] else 'Decision Tree'} is better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 9: Cross-Validation\n",
    "---\n",
    "\n",
    "## What is Cross-Validation?\n",
    "\n",
    "Cross-validation is a technique to evaluate model performance more reliably by training and testing on different subsets of data multiple times.\n",
    "\n",
    "### Why Use Cross-Validation?\n",
    "\n",
    "- **More reliable estimates**: Single train-test split can be misleading\n",
    "- **Better use of data**: All data points are used for both training and testing\n",
    "- **Detect overfitting**: Large gap between training and CV scores indicates overfitting\n",
    "\n",
    "### K-Fold Cross-Validation\n",
    "\n",
    "1. Split data into K equal folds\n",
    "2. For each fold:\n",
    "   - Use that fold as test set\n",
    "   - Use remaining K-1 folds as training set\n",
    "   - Calculate performance metric\n",
    "3. Average the K results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "# Basic cross-validation\n",
    "scores = cross_val_score(\n",
    "    model,           # The model to evaluate\n",
    "    X,               # Features\n",
    "    y,               # Target\n",
    "    cv=5,            # Number of folds\n",
    "    scoring='accuracy'  # Metric to use\n",
    ")\n",
    "\n",
    "print(f\"Mean: {scores.mean():.4f}\")\n",
    "print(f\"Std: {scores.std():.4f}\")\n",
    "\n",
    "# Custom K-Fold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "# Stratified K-Fold (for classification)\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=skfold)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-Fold Cross-Validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create sample data indices\n",
    "n_samples = 25\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "# Set up 5-fold CV\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(indices)):\n",
    "    # Plot training indices\n",
    "    ax.scatter(train_idx, [fold_idx] * len(train_idx), c='steelblue', s=100, \n",
    "               label='Training' if fold_idx == 0 else '')\n",
    "    # Plot test indices\n",
    "    ax.scatter(test_idx, [fold_idx] * len(test_idx), c='coral', s=100,\n",
    "               label='Testing' if fold_idx == 0 else '')\n",
    "\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Fold')\n",
    "ax.set_yticks(range(5))\n",
    "ax.set_yticklabels([f'Fold {i+1}' for i in range(5)])\n",
    "ax.set_title('5-Fold Cross-Validation Visualization')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cross-validation to our models\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "print(\"Cross-Validation Results (5-Fold)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use stratified K-fold for classification\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_cv = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_scores = cross_val_score(lr_cv, scaler.fit_transform(X), y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nLogistic Regression:\")\n",
    "print(f\"  Scores per fold: {[f'{s:.4f}' for s in lr_scores]}\")\n",
    "print(f\"  Mean accuracy: {lr_scores.mean():.4f} (+/- {lr_scores.std()*2:.4f})\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_cv = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dt_scores = cross_val_score(dt_cv, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nDecision Tree:\")\n",
    "print(f\"  Scores per fold: {[f'{s:.4f}' for s in dt_scores]}\")\n",
    "print(f\"  Mean accuracy: {dt_scores.mean():.4f} (+/- {dt_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models with multiple metrics using cross-validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_cv_results = cross_validate(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    scaler.fit_transform(X), y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "dt_cv_results = cross_validate(\n",
    "    DecisionTreeClassifier(max_depth=4, random_state=42),\n",
    "    X, y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Create comparison table\n",
    "print(\"Comprehensive Cross-Validation Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric in scoring:\n",
    "    lr_test = lr_cv_results[f'test_{metric}']\n",
    "    dt_test = dt_cv_results[f'test_{metric}']\n",
    "    \n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Logistic Regression: {lr_test.mean():.4f} (+/- {lr_test.std()*2:.4f})\")\n",
    "    print(f\"  Decision Tree:       {dt_test.mean():.4f} (+/- {dt_test.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validation results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "lr_means = [lr_cv_results[f'test_{m.lower()}'].mean() for m in metrics]\n",
    "lr_stds = [lr_cv_results[f'test_{m.lower()}'].std() for m in metrics]\n",
    "dt_means = [dt_cv_results[f'test_{m.lower()}'].mean() for m in metrics]\n",
    "dt_stds = [dt_cv_results[f'test_{m.lower()}'].std() for m in metrics]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, lr_means, width, yerr=lr_stds, label='Logistic Regression', capsize=5)\n",
    "bars2 = ax.bar(x + width/2, dt_means, width, yerr=dt_stds, label='Decision Tree', capsize=5)\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Cross-Validation Results Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 10: Introduction to Scikit-Learn\n",
    "---\n",
    "\n",
    "## What is Scikit-Learn?\n",
    "\n",
    "Scikit-learn is the most popular machine learning library in Python. It provides:\n",
    "\n",
    "- **Simple and consistent API**: All models follow the same pattern\n",
    "- **Comprehensive algorithms**: Classification, regression, clustering, etc.\n",
    "- **Data preprocessing tools**: Scaling, encoding, imputation\n",
    "- **Model selection utilities**: Cross-validation, hyperparameter tuning\n",
    "- **Excellent documentation**: Well-documented with examples\n",
    "\n",
    "## The Scikit-Learn API Pattern\n",
    "\n",
    "All scikit-learn estimators follow the same pattern:\n",
    "\n",
    "```python\n",
    "# 1. Import\n",
    "from sklearn.module import EstimatorClass\n",
    "\n",
    "# 2. Instantiate\n",
    "model = EstimatorClass(hyperparameters)\n",
    "\n",
    "# 3. Fit (train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "score = model.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of common scikit-learn modules\n",
    "print(\"Scikit-Learn Module Overview\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "modules = [\n",
    "    (\"sklearn.linear_model\", \"Linear models\", \n",
    "     [\"LinearRegression\", \"LogisticRegression\", \"Ridge\", \"Lasso\"]),\n",
    "    (\"sklearn.tree\", \"Tree-based models\",\n",
    "     [\"DecisionTreeClassifier\", \"DecisionTreeRegressor\"]),\n",
    "    (\"sklearn.ensemble\", \"Ensemble methods\",\n",
    "     [\"RandomForestClassifier\", \"GradientBoostingClassifier\"]),\n",
    "    (\"sklearn.svm\", \"Support Vector Machines\",\n",
    "     [\"SVC\", \"SVR\"]),\n",
    "    (\"sklearn.neighbors\", \"Nearest Neighbors\",\n",
    "     [\"KNeighborsClassifier\", \"KNeighborsRegressor\"]),\n",
    "    (\"sklearn.cluster\", \"Clustering\",\n",
    "     [\"KMeans\", \"DBSCAN\", \"AgglomerativeClustering\"]),\n",
    "    (\"sklearn.preprocessing\", \"Data preprocessing\",\n",
    "     [\"StandardScaler\", \"MinMaxScaler\", \"LabelEncoder\"]),\n",
    "    (\"sklearn.model_selection\", \"Model selection\",\n",
    "     [\"train_test_split\", \"cross_val_score\", \"GridSearchCV\"]),\n",
    "    (\"sklearn.metrics\", \"Evaluation metrics\",\n",
    "     [\"accuracy_score\", \"mean_squared_error\", \"confusion_matrix\"])\n",
    "]\n",
    "\n",
    "for module, description, classes in modules:\n",
    "    print(f\"\\n{module}\")\n",
    "    print(f\"  {description}\")\n",
    "    print(f\"  Classes: {', '.join(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete ML pipeline with scikit-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Building a Complete ML Pipeline\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a pipeline that combines preprocessing and modeling\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),           # Step 1: Scale features\n",
    "    ('classifier', LogisticRegression())    # Step 2: Train classifier\n",
    "])\n",
    "\n",
    "# Fit the entire pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the pipeline\n",
    "y_pred_pipeline = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"\\nPipeline Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Cross-validate the entire pipeline\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(f\"\\nCross-Validation Scores: {[f'{s:.4f}' for s in cv_scores]}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Hyperparameter Tuning with GridSearchCV\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [5, 10, 20],\n",
    "    'min_samples_leaf': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Plot heatmap of results for different max_depth and min_samples_split\n",
    "# (fixing min_samples_leaf at the best value)\n",
    "best_leaf = grid_search.best_params_['min_samples_leaf']\n",
    "subset = results_df[results_df['param_min_samples_leaf'] == best_leaf]\n",
    "\n",
    "pivot_table = subset.pivot_table(\n",
    "    values='mean_test_score',\n",
    "    index='param_max_depth',\n",
    "    columns='param_min_samples_split'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.4f', cmap='YlGnBu')\n",
    "plt.title(f'Grid Search Results (min_samples_leaf={best_leaf})')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('max_depth')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise 10.1\n",
    "\n",
    "**Task:** Use scikit-learn to build a complete machine learning solution for the Iris dataset.\n",
    "\n",
    "Steps:\n",
    "1. Load the Iris dataset using `load_iris()`\n",
    "2. Split into training and testing sets\n",
    "3. Create a pipeline with StandardScaler and LogisticRegression\n",
    "4. Perform 5-fold cross-validation\n",
    "5. Use GridSearchCV to tune the `C` parameter (try [0.01, 0.1, 1, 10, 100])\n",
    "6. Report the best parameters and test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(f\"Dataset shape: {X_iris.shape}\")\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Classes: {iris.target_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 10.1\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# Step 1: Load dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(\"Step 1: Load Dataset\")\n",
    "print(f\"  Shape: {X_iris.shape}\")\n",
    "print(f\"  Classes: {list(iris.target_names)}\")\n",
    "\n",
    "# Step 2: Split data\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, stratify=y_iris, random_state=42\n",
    ")\n",
    "print(f\"\\nStep 2: Split Data\")\n",
    "print(f\"  Training samples: {len(X_train_i)}\")\n",
    "print(f\"  Testing samples: {len(X_test_i)}\")\n",
    "\n",
    "# Step 3: Create pipeline\n",
    "pipeline_iris = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "print(f\"\\nStep 3: Pipeline Created\")\n",
    "print(f\"  Steps: {[step[0] for step in pipeline_iris.steps]}\")\n",
    "\n",
    "# Step 4: Cross-validation\n",
    "cv_scores_iris = cross_val_score(pipeline_iris, X_train_i, y_train_i, cv=5)\n",
    "print(f\"\\nStep 4: Cross-Validation\")\n",
    "print(f\"  Scores: {[f'{s:.4f}' for s in cv_scores_iris]}\")\n",
    "print(f\"  Mean: {cv_scores_iris.mean():.4f} (+/- {cv_scores_iris.std()*2:.4f})\")\n",
    "\n",
    "# Step 5: GridSearchCV\n",
    "param_grid_iris = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_iris = GridSearchCV(pipeline_iris, param_grid_iris, cv=5, scoring='accuracy')\n",
    "grid_iris.fit(X_train_i, y_train_i)\n",
    "\n",
    "print(f\"\\nStep 5: GridSearchCV\")\n",
    "print(f\"  Best C: {grid_iris.best_params_['classifier__C']}\")\n",
    "print(f\"  Best CV Score: {grid_iris.best_score_:.4f}\")\n",
    "\n",
    "# Step 6: Final evaluation\n",
    "test_accuracy_iris = grid_iris.score(X_test_i, y_test_i)\n",
    "print(f\"\\nStep 6: Final Evaluation\")\n",
    "print(f\"  Test Set Accuracy: {test_accuracy_iris:.4f}\")\n",
    "\n",
    "# Detailed results\n",
    "print(f\"\\nClassification Report:\")\n",
    "y_pred_iris = grid_iris.predict(X_test_i)\n",
    "print(classification_report(y_test_i, y_pred_iris, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Module Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### What is Machine Learning?\n",
    "- ML enables computers to learn patterns from data without explicit programming\n",
    "- Three main types: Supervised, Unsupervised, and Reinforcement Learning\n",
    "- Supervised learning includes regression (continuous) and classification (categorical)\n",
    "\n",
    "### The ML Workflow\n",
    "1. Define the problem\n",
    "2. Collect and prepare data\n",
    "3. Explore data (EDA)\n",
    "4. Build and train models\n",
    "5. Evaluate performance\n",
    "6. Fine-tune and deploy\n",
    "\n",
    "### Train-Test Split\n",
    "- Always split data before training\n",
    "- Common ratio: 80% training, 20% testing\n",
    "- Use stratification for imbalanced classification problems\n",
    "\n",
    "### Algorithms Covered\n",
    "- **Linear Regression**: Predicts continuous values, interpretable coefficients\n",
    "- **Logistic Regression**: Binary classification using sigmoid function\n",
    "- **Decision Trees**: Interpretable, handles non-linear relationships\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Regression**: MSE, RMSE, MAE, R-squared\n",
    "- **Classification**: Accuracy, Precision, Recall, F1-score, ROC-AUC\n",
    "- Choose metrics based on business context\n",
    "\n",
    "### Cross-Validation\n",
    "- More reliable than single train-test split\n",
    "- K-Fold CV uses all data for both training and testing\n",
    "- Report mean and standard deviation\n",
    "\n",
    "### Scikit-Learn\n",
    "- Consistent API: fit(), predict(), score()\n",
    "- Pipelines combine preprocessing and modeling\n",
    "- GridSearchCV for hyperparameter tuning\n",
    "\n",
    "## Next Module\n",
    "In the final module, we'll apply everything we've learned to real-world Capstone Projects, including sales analysis, customer segmentation, and predictive modeling.\n",
    "\n",
    "## Additional Practice\n",
    "For extra practice, try these challenges:\n",
    "1. Load a dataset from Kaggle and apply the complete ML workflow\n",
    "2. Compare at least 3 different algorithms on the same problem\n",
    "3. Implement feature engineering to improve model performance\n",
    "4. Create an end-to-end pipeline with preprocessing, modeling, and evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
